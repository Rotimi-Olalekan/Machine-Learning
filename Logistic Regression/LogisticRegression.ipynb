{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression from Scratch\n",
    "\n",
    "\n",
    "Hello Everyone. In this tutorial, we will implement Logistic Regression from scratch. \n",
    "\n",
    "So, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step-1 Import Dependencies\n",
    "\n",
    "#### numpy:\n",
    "for numerical calculations\n",
    "\n",
    "#### pandas:\n",
    "for data modelling and access data from files\n",
    "\n",
    "#### matplotlib:\n",
    "to plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step-2: Define the Hypothesis\n",
    "\n",
    "Next step is to define our hypothesis. As we saw in the theory part that the hypothesis for Logistic Regression is same as the Linear Regression but with only one minor difference i.e. in Logistic Regression we take the Sigmoid of the hypothesis before going further with it.\n",
    "\n",
    "So, let's define these things first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid Function\n",
    "# sigmoid(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return float(1.0 / float(1.0 + np.exp(-1.0 * z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hypothesis Function\n",
    "# y_hat = m*X\n",
    "# Hypothesis = sigmoid(y_hat) => sigmoid(m*X)\n",
    "\n",
    "def hypothesis(m, X):\n",
    "    z = 0\n",
    "    for i in range(len(m)):\n",
    "        z += X[i] * m[i]\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step-3: Cost Function\n",
    "\n",
    "So, if we see the theory for Logistic Regression and look at the mathematics in that, our next step seems to be forming a Cost Function for Logistic Regression.\n",
    "\n",
    "So, let's write our Cost Function.\n",
    "\n",
    "In theory, we defined our final Cost Function expression as follows:\n",
    "\n",
    "#### J = (1/n) [-y * log(sigmoid(m*X)) - (1 - y) * log(1 - sigmoid(m*X)) ]\n",
    "\n",
    "where,\n",
    "\n",
    "#### y : Class label [0 or 1]\n",
    "\n",
    "Also, we know that according to the value of the class i.e. 0 or 1, the cost function reduces to:\n",
    "\n",
    "#### J = -log(sigmoid(m*X))  for y = 1\n",
    "\n",
    "#### J = -log(1 - sigmoid(m*X))   for y = 0 \n",
    "\n",
    "So, let's write our cost function using these equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cost Function\n",
    "# J = (-1/n) [y log(sigmoid(mX + b)) + (1 - y) log(1 - sigmoid(mX + b))]\n",
    "\n",
    "def costFunction(X,y,m):\n",
    "    errorSum = 0\n",
    "    error = 0\n",
    "    n = len(y)\n",
    "    for i in range(n):\n",
    "        hy = hypothesis(m,X[i])\n",
    "        if y[i] == 1:\n",
    "            error = y[i] * np.log(hy)\n",
    "        elif y[i] == 0:\n",
    "            error = (1-y[i]) * np.log(1 - hy)\n",
    "        errorSum += error\n",
    "    J = (-1/n) * errorSum\n",
    "    print('Cost: ', J)\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So, now that we have defined our Cost Function, it's time to define our Gradient Descent Function. So, let's do it.\n",
    "\n",
    "\n",
    "## Step-4: Gradient Descend\n",
    "\n",
    "How does Gradient Descend works ?? We find the derivative of the Cost Function w.r.t \"m\" i.e. dJ/dm and then calculate the error. After this we update the value of m as:\n",
    "\n",
    "#### m := m - alpha * dJ/dm\n",
    "\n",
    "where,\n",
    "\n",
    "#### alpha: Learning Rate\n",
    "\n",
    "So, what is dJ/dm for this case ??\n",
    "\n",
    "Let's calculate it.\n",
    "\n",
    "#### J = (-1/n) [-y * log(sigmoid(m*X)) + (1 - y) * log(1 - sigmoid(m*X)) ]\n",
    "\n",
    "where, \n",
    "\n",
    "#### y_hat = sigmoid(m*X)\n",
    "\n",
    "So, the equation becomes:\n",
    "\n",
    "#### J = (-1/n) [-y * log(y_hat) + (1 - y) * log(1 - y_hat)]         - - - (i)\n",
    "\n",
    "and \n",
    "\n",
    "#### y_hat = 1/(1 + exp(-m*X))\n",
    "\n",
    "So, let's go step by step.\n",
    "\n",
    "#### log(y_hat) = 1 / (1 + exp(-mX))\n",
    "\n",
    "or\n",
    "\n",
    "#### log(y_hat) = -log(1 + exp(-mX))                        - - - (ii)\n",
    "\n",
    "\n",
    "Now the seocnd part of this equation.\n",
    "\n",
    "#### log(1 - y_hat) = log(1 - (1 / (1 + exp(-mX))))\n",
    "\n",
    "So, this can be written as:\n",
    "\n",
    "#### log(1 - y_hat) = log( exp(-mX) / (1 + exp(-mX)))\n",
    "\n",
    "which can be written as:\n",
    "\n",
    "#### log(1 - y_hat) = log(exp(-mX)) - log(1 +  exp(-mx))\n",
    "\n",
    "#### log(1 - y_hat) = -mX - log(1 + exp(-mX))           - - - (iii)\n",
    "\n",
    "Putting all these values in the equation of Cost Function, eqn (i), we get:\n",
    "\n",
    "\n",
    "#### J = (-1/n)  summation [ -y log(1 + exp(-mX)) + (1 - y) ( -mX - log(1 + exp(-mX)))]                 - - - (iv)\n",
    "\n",
    "which can be written as:\n",
    "\n",
    "#### J = (-1/n)  summation [ (y * mX) - mX - log(1 + exp(-mX)))]              - - - (v)\n",
    "\n",
    "Now, the second term in the equation (v) can be simplified as:\n",
    "\n",
    "#### [-mX - log(1 + exp(-mX))]    =   - [log(exp(-mX)) + log(1 + exp(-mx))]    =  - [log(1 + exp(-mX))]        - - - (vi)\n",
    "\n",
    "using the quality of \"log\" equation i.e. \n",
    "\n",
    "#### log(x) + log(y) = log(xy)\n",
    "\n",
    "Putting this equation to equation (v), we get:\n",
    "\n",
    "#### J = (-1/n)  summation [ (y * mX) - log(1 + exp(mX)))]             - - - (vii)\n",
    "\n",
    "Now, we have the final cost function. Let's calculate the derivative of this i.e. dJ/dm\n",
    "\n",
    "Taking first term first:\n",
    "\n",
    "#### d/dm (y*mX) = yX      - - - (viii (a))\n",
    "\n",
    "#### d/dm (log(1 + exp(mX)))  = ( X * exp(mx) ) / (1 + exp(mX))   =  X * (y_hat)         - - - (viii (b))\n",
    "\n",
    "\n",
    "From (viii) \"a\" and \"b\" we get the following final equation:\n",
    "\n",
    "### dJ/dm = (1/n) summation( y - y_hat) X             - - - (ix)\n",
    "\n",
    "\n",
    "So, to update the value of \"m\", we get the equation:\n",
    "\n",
    "### m : = m - alpha * dJ/dm\n",
    "\n",
    "\n",
    "Let's implement this function... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "# X,y: Features,Labels\n",
    "# m: Slope\n",
    "# lr: Learning Rate\n",
    "\n",
    "def gradientDescend(X,y,m,lr):\n",
    "    new_m = []\n",
    "    n = len(y)\n",
    "    const = lr/n\n",
    "    for j in range(len(m)):\n",
    "        errorSum = 0\n",
    "        for i in range(n):\n",
    "            Xi = X[i]\n",
    "            Xij = Xi[j]\n",
    "            hi = hypothesis(m, X[i])\n",
    "            error = (hi - y[i]) * Xij\n",
    "            errorSum += error\n",
    "        n = len(y)\n",
    "        const = float(lr) / float(n)\n",
    "        J = const * errorSum\n",
    "        updated_m = m[j] - J\n",
    "        new_m.append(updated_m)\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done with our Gradient Descend function, one last thig is left. This function currently will run only once whereas we know that to minimize the loss/cost, gradient descend requires more than one step down the slope.\n",
    "\n",
    "So, let's define that last function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Runner Function\n",
    "# X: Features\n",
    "# y: Labels\n",
    "# lr: Learning Rate\n",
    "# m: Slope\n",
    "# iters: Number of Iterations\n",
    "\n",
    "def runner(X,y,lr,m,iters):\n",
    "    n = len(y)\n",
    "    a = 0\n",
    "    hist = []\n",
    "    print('Starting Gradient Descend...\\n')\n",
    "    for x in range(iters):\n",
    "        new_m = gradientDescend(X,y,m,lr)\n",
    "        m = new_m\n",
    "        a = costFunction(X,y,m)\n",
    "        hist.append(a)\n",
    "        \n",
    "        # Print the information at every 100th step \n",
    "        if x % 100 == 0:\n",
    "            costFunction(X,y,m)\n",
    "            print('m: ', m)\n",
    "            print('Cost ', costFunction(X,y,m))\n",
    "            print('\\n')\n",
    "    return [m,hist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we are all done with our functions, let's load the data and finally test what all hardwork we have done till yet. Hold on just a bit longer...\n",
    "\n",
    "## Step-5: Load the Dataset\n",
    "\n",
    "For this tutorial, we will be using the \"Haberman's Survival Dataset\". You can download this dataset from here [https://archive.ics.uci.edu/ml/datasets/Haberman's+Survival].\n",
    "\n",
    "So, what is this dataset all about. Well, this dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n",
    "\n",
    "This dataset has the following attributes:\n",
    "1. Age of patient at time of operation (numerical) \n",
    "2. Patient's year of operation (year - 1900, numerical) \n",
    "3. Number of positive axillary nodes detected (numerical) \n",
    "4. Survival status (class attribute) \n",
    "-- 1 = the patient survived 5 years or longer \n",
    "-- 2 = the patient died within 5 year\n",
    "\n",
    "So, as you can see that this dataset classifies that whether a person survived more than 5 years or less than that based on his age, year of operation and the number of positive axillary nodes detected.\n",
    "\n",
    "Let's load the dataset and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>64</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   30  64   1  1.1\n",
       "0  30  62   3    1\n",
       "1  30  65   0    1\n",
       "2  31  59   2    1\n",
       "3  31  65   4    1\n",
       "4  33  58  10    1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "\n",
    "df = pd.read_csv('dataset/haberman-data.csv')\n",
    "\n",
    "# Let's have a look at it\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like our data does not have any labels. let's add labels to the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>year_operation</th>\n",
       "      <th>pos_auxillary_nodes</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  year_operation  pos_auxillary_nodes  survival_status\n",
       "0   30              62                    3                1\n",
       "1   30              65                    0                1\n",
       "2   31              59                    2                1\n",
       "3   31              65                    4                1\n",
       "4   33              58                   10                1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's give names to the Columns\n",
    "\n",
    "df.columns = ['age','year_operation','pos_auxillary_nodes','survival_status']\n",
    "\n",
    "# Let's check the data again\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it looks good. All columns have a name now. \n",
    "\n",
    "Let's describe it as well to check if its balaced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>year_operation</th>\n",
       "      <th>pos_auxillary_nodes</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>305.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.531148</td>\n",
       "      <td>62.849180</td>\n",
       "      <td>4.036066</td>\n",
       "      <td>1.265574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.744024</td>\n",
       "      <td>3.254078</td>\n",
       "      <td>7.199370</td>\n",
       "      <td>0.442364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  year_operation  pos_auxillary_nodes  survival_status\n",
       "count  305.000000      305.000000           305.000000       305.000000\n",
       "mean    52.531148       62.849180             4.036066         1.265574\n",
       "std     10.744024        3.254078             7.199370         0.442364\n",
       "min     30.000000       58.000000             0.000000         1.000000\n",
       "25%     44.000000       60.000000             0.000000         1.000000\n",
       "50%     52.000000       63.000000             1.000000         1.000000\n",
       "75%     61.000000       66.000000             4.000000         2.000000\n",
       "max     83.000000       69.000000            52.000000         2.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset looks pretty balanced to me. Now, to the nest step. Let's do feature selection.\n",
    "\n",
    "## Step-6: Feature Selection\n",
    "\n",
    "So, how do we do this ?? Correlation. Yes, you are right. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>year_operation</th>\n",
       "      <th>pos_auxillary_nodes</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092623</td>\n",
       "      <td>-0.066548</td>\n",
       "      <td>0.064351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_operation</th>\n",
       "      <td>0.092623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_auxillary_nodes</th>\n",
       "      <td>-0.066548</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survival_status</th>\n",
       "      <td>0.064351</td>\n",
       "      <td>-0.004076</td>\n",
       "      <td>0.286191</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          age  year_operation  pos_auxillary_nodes  \\\n",
       "age                  1.000000        0.092623            -0.066548   \n",
       "year_operation       0.092623        1.000000            -0.003277   \n",
       "pos_auxillary_nodes -0.066548       -0.003277             1.000000   \n",
       "survival_status      0.064351       -0.004076             0.286191   \n",
       "\n",
       "                     survival_status  \n",
       "age                         0.064351  \n",
       "year_operation             -0.004076  \n",
       "pos_auxillary_nodes         0.286191  \n",
       "survival_status             1.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, this dataset has less number of features and from the correlation report all of them look important. So, let's take them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  [[30 62  3]\n",
      " [30 65  0]\n",
      " [31 59  2]\n",
      " [31 65  4]\n",
      " [33 58 10]\n",
      " [33 60  0]\n",
      " [34 59  0]\n",
      " [34 66  9]\n",
      " [34 58 30]\n",
      " [34 60  1]\n",
      " [34 61 10]\n",
      " [34 67  7]\n",
      " [34 60  0]\n",
      " [35 64 13]\n",
      " [35 63  0]\n",
      " [36 60  1]\n",
      " [36 69  0]\n",
      " [37 60  0]\n",
      " [37 63  0]\n",
      " [37 58  0]\n",
      " [37 59  6]\n",
      " [37 60 15]\n",
      " [37 63  0]\n",
      " [38 69 21]\n",
      " [38 59  2]\n",
      " [38 60  0]\n",
      " [38 60  0]\n",
      " [38 62  3]\n",
      " [38 64  1]\n",
      " [38 66  0]\n",
      " [38 66 11]\n",
      " [38 60  1]\n",
      " [38 67  5]\n",
      " [39 66  0]\n",
      " [39 63  0]\n",
      " [39 67  0]\n",
      " [39 58  0]\n",
      " [39 59  2]\n",
      " [39 63  4]\n",
      " [40 58  2]\n",
      " [40 58  0]\n",
      " [40 65  0]\n",
      " [41 60 23]\n",
      " [41 64  0]\n",
      " [41 67  0]\n",
      " [41 58  0]\n",
      " [41 59  8]\n",
      " [41 59  0]\n",
      " [41 64  0]\n",
      " [41 69  8]\n",
      " [41 65  0]\n",
      " [41 65  0]\n",
      " [42 69  1]\n",
      " [42 59  0]\n",
      " [42 58  0]\n",
      " [42 60  1]\n",
      " [42 59  2]\n",
      " [42 61  4]\n",
      " [42 62 20]\n",
      " [42 65  0]\n",
      " [42 63  1]\n",
      " [43 58 52]\n",
      " [43 59  2]\n",
      " [43 64  0]\n",
      " [43 64  0]\n",
      " [43 63 14]\n",
      " [43 64  2]\n",
      " [43 64  3]\n",
      " [43 60  0]\n",
      " [43 63  2]\n",
      " [43 65  0]\n",
      " [43 66  4]\n",
      " [44 64  6]\n",
      " [44 58  9]\n",
      " [44 63 19]\n",
      " [44 61  0]\n",
      " [44 63  1]\n",
      " [44 61  0]\n",
      " [44 67 16]\n",
      " [45 65  6]\n",
      " [45 66  0]\n",
      " [45 67  1]\n",
      " [45 60  0]\n",
      " [45 67  0]\n",
      " [45 59 14]\n",
      " [45 64  0]\n",
      " [45 68  0]\n",
      " [45 67  1]\n",
      " [46 58  2]\n",
      " [46 69  3]\n",
      " [46 62  5]\n",
      " [46 65 20]\n",
      " [46 62  0]\n",
      " [46 58  3]\n",
      " [46 63  0]\n",
      " [47 63 23]\n",
      " [47 62  0]\n",
      " [47 65  0]\n",
      " [47 61  0]\n",
      " [47 63  6]\n",
      " [47 66  0]\n",
      " [47 67  0]\n",
      " [47 58  3]\n",
      " [47 60  4]\n",
      " [47 68  4]\n",
      " [47 66 12]\n",
      " [48 58 11]\n",
      " [48 58 11]\n",
      " [48 67  7]\n",
      " [48 61  8]\n",
      " [48 62  2]\n",
      " [48 64  0]\n",
      " [48 66  0]\n",
      " [49 63  0]\n",
      " [49 64 10]\n",
      " [49 61  1]\n",
      " [49 62  0]\n",
      " [49 66  0]\n",
      " [49 60  1]\n",
      " [49 62  1]\n",
      " [49 63  3]\n",
      " [49 61  0]\n",
      " [49 67  1]\n",
      " [50 63 13]\n",
      " [50 64  0]\n",
      " [50 59  0]\n",
      " [50 61  6]\n",
      " [50 61  0]\n",
      " [50 63  1]\n",
      " [50 58  1]\n",
      " [50 59  2]\n",
      " [50 61  0]\n",
      " [50 64  0]\n",
      " [50 65  4]\n",
      " [50 66  1]\n",
      " [51 59 13]\n",
      " [51 59  3]\n",
      " [51 64  7]\n",
      " [51 59  1]\n",
      " [51 65  0]\n",
      " [51 66  1]\n",
      " [52 69  3]\n",
      " [52 59  2]\n",
      " [52 62  3]\n",
      " [52 66  4]\n",
      " [52 61  0]\n",
      " [52 63  4]\n",
      " [52 69  0]\n",
      " [52 60  4]\n",
      " [52 60  5]\n",
      " [52 62  0]\n",
      " [52 62  1]\n",
      " [52 64  0]\n",
      " [52 65  0]\n",
      " [52 68  0]\n",
      " [53 58  4]\n",
      " [53 65  1]\n",
      " [53 59  3]\n",
      " [53 60  9]\n",
      " [53 63 24]\n",
      " [53 65 12]\n",
      " [53 58  1]\n",
      " [53 60  1]\n",
      " [53 60  2]\n",
      " [53 61  1]\n",
      " [53 63  0]\n",
      " [54 60 11]\n",
      " [54 65 23]\n",
      " [54 65  5]\n",
      " [54 68  7]\n",
      " [54 59  7]\n",
      " [54 60  3]\n",
      " [54 66  0]\n",
      " [54 67 46]\n",
      " [54 62  0]\n",
      " [54 69  7]\n",
      " [54 63 19]\n",
      " [54 58  1]\n",
      " [54 62  0]\n",
      " [55 63  6]\n",
      " [55 68 15]\n",
      " [55 58  1]\n",
      " [55 58  0]\n",
      " [55 58  1]\n",
      " [55 66 18]\n",
      " [55 66  0]\n",
      " [55 69  3]\n",
      " [55 69 22]\n",
      " [55 67  1]\n",
      " [56 65  9]\n",
      " [56 66  3]\n",
      " [56 60  0]\n",
      " [56 66  2]\n",
      " [56 66  1]\n",
      " [56 67  0]\n",
      " [56 60  0]\n",
      " [57 61  5]\n",
      " [57 62 14]\n",
      " [57 64  1]\n",
      " [57 64  9]\n",
      " [57 69  0]\n",
      " [57 61  0]\n",
      " [57 62  0]\n",
      " [57 63  0]\n",
      " [57 64  0]\n",
      " [57 64  0]\n",
      " [57 67  0]\n",
      " [58 59  0]\n",
      " [58 60  3]\n",
      " [58 61  1]\n",
      " [58 67  0]\n",
      " [58 58  0]\n",
      " [58 58  3]\n",
      " [58 61  2]\n",
      " [59 62 35]\n",
      " [59 60  0]\n",
      " [59 63  0]\n",
      " [59 64  1]\n",
      " [59 64  4]\n",
      " [59 64  0]\n",
      " [59 64  7]\n",
      " [59 67  3]\n",
      " [60 59 17]\n",
      " [60 65  0]\n",
      " [60 61  1]\n",
      " [60 67  2]\n",
      " [60 61 25]\n",
      " [60 64  0]\n",
      " [61 62  5]\n",
      " [61 65  0]\n",
      " [61 68  1]\n",
      " [61 59  0]\n",
      " [61 59  0]\n",
      " [61 64  0]\n",
      " [61 65  8]\n",
      " [61 68  0]\n",
      " [61 59  0]\n",
      " [62 59 13]\n",
      " [62 58  0]\n",
      " [62 65 19]\n",
      " [62 62  6]\n",
      " [62 66  0]\n",
      " [62 66  0]\n",
      " [62 58  0]\n",
      " [63 60  1]\n",
      " [63 61  0]\n",
      " [63 62  0]\n",
      " [63 63  0]\n",
      " [63 63  0]\n",
      " [63 66  0]\n",
      " [63 61  9]\n",
      " [63 61 28]\n",
      " [64 58  0]\n",
      " [64 65 22]\n",
      " [64 66  0]\n",
      " [64 61  0]\n",
      " [64 68  0]\n",
      " [65 58  0]\n",
      " [65 61  2]\n",
      " [65 62 22]\n",
      " [65 66 15]\n",
      " [65 58  0]\n",
      " [65 64  0]\n",
      " [65 67  0]\n",
      " [65 59  2]\n",
      " [65 64  0]\n",
      " [65 67  1]\n",
      " [66 58  0]\n",
      " [66 61 13]\n",
      " [66 58  0]\n",
      " [66 58  1]\n",
      " [66 68  0]\n",
      " [67 64  8]\n",
      " [67 63  1]\n",
      " [67 66  0]\n",
      " [67 66  0]\n",
      " [67 61  0]\n",
      " [67 65  0]\n",
      " [68 67  0]\n",
      " [68 68  0]\n",
      " [69 67  8]\n",
      " [69 60  0]\n",
      " [69 65  0]\n",
      " [69 66  0]\n",
      " [70 58  0]\n",
      " [70 58  4]\n",
      " [70 66 14]\n",
      " [70 67  0]\n",
      " [70 68  0]\n",
      " [70 59  8]\n",
      " [70 63  0]\n",
      " [71 68  2]\n",
      " [72 63  0]\n",
      " [72 58  0]\n",
      " [72 64  0]\n",
      " [72 67  3]\n",
      " [73 62  0]\n",
      " [73 68  0]\n",
      " [74 65  3]\n",
      " [74 63  0]\n",
      " [75 62  1]\n",
      " [76 67  0]\n",
      " [77 65  3]\n",
      " [78 65  1]\n",
      " [83 58  2]]\n"
     ]
    }
   ],
   "source": [
    "# Features:\n",
    "\n",
    "X = np.array(df[['age','year_operation','pos_auxillary_nodes']])\n",
    "print('Features: ',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Features:  [[-1.         -0.27272727 -0.88461538]\n",
      " [-1.          0.27272727 -1.        ]\n",
      " [-0.96226415 -0.81818182 -0.92307692]\n",
      " [-0.96226415  0.27272727 -0.84615385]\n",
      " [-0.88679245 -1.         -0.61538462]\n",
      " [-0.88679245 -0.63636364 -1.        ]\n",
      " [-0.8490566  -0.81818182 -1.        ]\n",
      " [-0.8490566   0.45454545 -0.65384615]\n",
      " [-0.8490566  -1.          0.15384615]\n",
      " [-0.8490566  -0.63636364 -0.96153846]\n",
      " [-0.8490566  -0.45454545 -0.61538462]\n",
      " [-0.8490566   0.63636364 -0.73076923]\n",
      " [-0.8490566  -0.63636364 -1.        ]\n",
      " [-0.81132075  0.09090909 -0.5       ]\n",
      " [-0.81132075 -0.09090909 -1.        ]\n",
      " [-0.77358491 -0.63636364 -0.96153846]\n",
      " [-0.77358491  1.         -1.        ]\n",
      " [-0.73584906 -0.63636364 -1.        ]\n",
      " [-0.73584906 -0.09090909 -1.        ]\n",
      " [-0.73584906 -1.         -1.        ]\n",
      " [-0.73584906 -0.81818182 -0.76923077]\n",
      " [-0.73584906 -0.63636364 -0.42307692]\n",
      " [-0.73584906 -0.09090909 -1.        ]\n",
      " [-0.69811321  1.         -0.19230769]\n",
      " [-0.69811321 -0.81818182 -0.92307692]\n",
      " [-0.69811321 -0.63636364 -1.        ]\n",
      " [-0.69811321 -0.63636364 -1.        ]\n",
      " [-0.69811321 -0.27272727 -0.88461538]\n",
      " [-0.69811321  0.09090909 -0.96153846]\n",
      " [-0.69811321  0.45454545 -1.        ]\n",
      " [-0.69811321  0.45454545 -0.57692308]\n",
      " [-0.69811321 -0.63636364 -0.96153846]\n",
      " [-0.69811321  0.63636364 -0.80769231]\n",
      " [-0.66037736  0.45454545 -1.        ]\n",
      " [-0.66037736 -0.09090909 -1.        ]\n",
      " [-0.66037736  0.63636364 -1.        ]\n",
      " [-0.66037736 -1.         -1.        ]\n",
      " [-0.66037736 -0.81818182 -0.92307692]\n",
      " [-0.66037736 -0.09090909 -0.84615385]\n",
      " [-0.62264151 -1.         -0.92307692]\n",
      " [-0.62264151 -1.         -1.        ]\n",
      " [-0.62264151  0.27272727 -1.        ]\n",
      " [-0.58490566 -0.63636364 -0.11538462]\n",
      " [-0.58490566  0.09090909 -1.        ]\n",
      " [-0.58490566  0.63636364 -1.        ]\n",
      " [-0.58490566 -1.         -1.        ]\n",
      " [-0.58490566 -0.81818182 -0.69230769]\n",
      " [-0.58490566 -0.81818182 -1.        ]\n",
      " [-0.58490566  0.09090909 -1.        ]\n",
      " [-0.58490566  1.         -0.69230769]\n",
      " [-0.58490566  0.27272727 -1.        ]\n",
      " [-0.58490566  0.27272727 -1.        ]\n",
      " [-0.54716981  1.         -0.96153846]\n",
      " [-0.54716981 -0.81818182 -1.        ]\n",
      " [-0.54716981 -1.         -1.        ]\n",
      " [-0.54716981 -0.63636364 -0.96153846]\n",
      " [-0.54716981 -0.81818182 -0.92307692]\n",
      " [-0.54716981 -0.45454545 -0.84615385]\n",
      " [-0.54716981 -0.27272727 -0.23076923]\n",
      " [-0.54716981  0.27272727 -1.        ]\n",
      " [-0.54716981 -0.09090909 -0.96153846]\n",
      " [-0.50943396 -1.          1.        ]\n",
      " [-0.50943396 -0.81818182 -0.92307692]\n",
      " [-0.50943396  0.09090909 -1.        ]\n",
      " [-0.50943396  0.09090909 -1.        ]\n",
      " [-0.50943396 -0.09090909 -0.46153846]\n",
      " [-0.50943396  0.09090909 -0.92307692]\n",
      " [-0.50943396  0.09090909 -0.88461538]\n",
      " [-0.50943396 -0.63636364 -1.        ]\n",
      " [-0.50943396 -0.09090909 -0.92307692]\n",
      " [-0.50943396  0.27272727 -1.        ]\n",
      " [-0.50943396  0.45454545 -0.84615385]\n",
      " [-0.47169811  0.09090909 -0.76923077]\n",
      " [-0.47169811 -1.         -0.65384615]\n",
      " [-0.47169811 -0.09090909 -0.26923077]\n",
      " [-0.47169811 -0.45454545 -1.        ]\n",
      " [-0.47169811 -0.09090909 -0.96153846]\n",
      " [-0.47169811 -0.45454545 -1.        ]\n",
      " [-0.47169811  0.63636364 -0.38461538]\n",
      " [-0.43396226  0.27272727 -0.76923077]\n",
      " [-0.43396226  0.45454545 -1.        ]\n",
      " [-0.43396226  0.63636364 -0.96153846]\n",
      " [-0.43396226 -0.63636364 -1.        ]\n",
      " [-0.43396226  0.63636364 -1.        ]\n",
      " [-0.43396226 -0.81818182 -0.46153846]\n",
      " [-0.43396226  0.09090909 -1.        ]\n",
      " [-0.43396226  0.81818182 -1.        ]\n",
      " [-0.43396226  0.63636364 -0.96153846]\n",
      " [-0.39622642 -1.         -0.92307692]\n",
      " [-0.39622642  1.         -0.88461538]\n",
      " [-0.39622642 -0.27272727 -0.80769231]\n",
      " [-0.39622642  0.27272727 -0.23076923]\n",
      " [-0.39622642 -0.27272727 -1.        ]\n",
      " [-0.39622642 -1.         -0.88461538]\n",
      " [-0.39622642 -0.09090909 -1.        ]\n",
      " [-0.35849057 -0.09090909 -0.11538462]\n",
      " [-0.35849057 -0.27272727 -1.        ]\n",
      " [-0.35849057  0.27272727 -1.        ]\n",
      " [-0.35849057 -0.45454545 -1.        ]\n",
      " [-0.35849057 -0.09090909 -0.76923077]\n",
      " [-0.35849057  0.45454545 -1.        ]\n",
      " [-0.35849057  0.63636364 -1.        ]\n",
      " [-0.35849057 -1.         -0.88461538]\n",
      " [-0.35849057 -0.63636364 -0.84615385]\n",
      " [-0.35849057  0.81818182 -0.84615385]\n",
      " [-0.35849057  0.45454545 -0.53846154]\n",
      " [-0.32075472 -1.         -0.57692308]\n",
      " [-0.32075472 -1.         -0.57692308]\n",
      " [-0.32075472  0.63636364 -0.73076923]\n",
      " [-0.32075472 -0.45454545 -0.69230769]\n",
      " [-0.32075472 -0.27272727 -0.92307692]\n",
      " [-0.32075472  0.09090909 -1.        ]\n",
      " [-0.32075472  0.45454545 -1.        ]\n",
      " [-0.28301887 -0.09090909 -1.        ]\n",
      " [-0.28301887  0.09090909 -0.61538462]\n",
      " [-0.28301887 -0.45454545 -0.96153846]\n",
      " [-0.28301887 -0.27272727 -1.        ]\n",
      " [-0.28301887  0.45454545 -1.        ]\n",
      " [-0.28301887 -0.63636364 -0.96153846]\n",
      " [-0.28301887 -0.27272727 -0.96153846]\n",
      " [-0.28301887 -0.09090909 -0.88461538]\n",
      " [-0.28301887 -0.45454545 -1.        ]\n",
      " [-0.28301887  0.63636364 -0.96153846]\n",
      " [-0.24528302 -0.09090909 -0.5       ]\n",
      " [-0.24528302  0.09090909 -1.        ]\n",
      " [-0.24528302 -0.81818182 -1.        ]\n",
      " [-0.24528302 -0.45454545 -0.76923077]\n",
      " [-0.24528302 -0.45454545 -1.        ]\n",
      " [-0.24528302 -0.09090909 -0.96153846]\n",
      " [-0.24528302 -1.         -0.96153846]\n",
      " [-0.24528302 -0.81818182 -0.92307692]\n",
      " [-0.24528302 -0.45454545 -1.        ]\n",
      " [-0.24528302  0.09090909 -1.        ]\n",
      " [-0.24528302  0.27272727 -0.84615385]\n",
      " [-0.24528302  0.45454545 -0.96153846]\n",
      " [-0.20754717 -0.81818182 -0.5       ]\n",
      " [-0.20754717 -0.81818182 -0.88461538]\n",
      " [-0.20754717  0.09090909 -0.73076923]\n",
      " [-0.20754717 -0.81818182 -0.96153846]\n",
      " [-0.20754717  0.27272727 -1.        ]\n",
      " [-0.20754717  0.45454545 -0.96153846]\n",
      " [-0.16981132  1.         -0.88461538]\n",
      " [-0.16981132 -0.81818182 -0.92307692]\n",
      " [-0.16981132 -0.27272727 -0.88461538]\n",
      " [-0.16981132  0.45454545 -0.84615385]\n",
      " [-0.16981132 -0.45454545 -1.        ]\n",
      " [-0.16981132 -0.09090909 -0.84615385]\n",
      " [-0.16981132  1.         -1.        ]\n",
      " [-0.16981132 -0.63636364 -0.84615385]\n",
      " [-0.16981132 -0.63636364 -0.80769231]\n",
      " [-0.16981132 -0.27272727 -1.        ]\n",
      " [-0.16981132 -0.27272727 -0.96153846]\n",
      " [-0.16981132  0.09090909 -1.        ]\n",
      " [-0.16981132  0.27272727 -1.        ]\n",
      " [-0.16981132  0.81818182 -1.        ]\n",
      " [-0.13207547 -1.         -0.84615385]\n",
      " [-0.13207547  0.27272727 -0.96153846]\n",
      " [-0.13207547 -0.81818182 -0.88461538]\n",
      " [-0.13207547 -0.63636364 -0.65384615]\n",
      " [-0.13207547 -0.09090909 -0.07692308]\n",
      " [-0.13207547  0.27272727 -0.53846154]\n",
      " [-0.13207547 -1.         -0.96153846]\n",
      " [-0.13207547 -0.63636364 -0.96153846]\n",
      " [-0.13207547 -0.63636364 -0.92307692]\n",
      " [-0.13207547 -0.45454545 -0.96153846]\n",
      " [-0.13207547 -0.09090909 -1.        ]\n",
      " [-0.09433962 -0.63636364 -0.57692308]\n",
      " [-0.09433962  0.27272727 -0.11538462]\n",
      " [-0.09433962  0.27272727 -0.80769231]\n",
      " [-0.09433962  0.81818182 -0.73076923]\n",
      " [-0.09433962 -0.81818182 -0.73076923]\n",
      " [-0.09433962 -0.63636364 -0.88461538]\n",
      " [-0.09433962  0.45454545 -1.        ]\n",
      " [-0.09433962  0.63636364  0.76923077]\n",
      " [-0.09433962 -0.27272727 -1.        ]\n",
      " [-0.09433962  1.         -0.73076923]\n",
      " [-0.09433962 -0.09090909 -0.26923077]\n",
      " [-0.09433962 -1.         -0.96153846]\n",
      " [-0.09433962 -0.27272727 -1.        ]\n",
      " [-0.05660377 -0.09090909 -0.76923077]\n",
      " [-0.05660377  0.81818182 -0.42307692]\n",
      " [-0.05660377 -1.         -0.96153846]\n",
      " [-0.05660377 -1.         -1.        ]\n",
      " [-0.05660377 -1.         -0.96153846]\n",
      " [-0.05660377  0.45454545 -0.30769231]\n",
      " [-0.05660377  0.45454545 -1.        ]\n",
      " [-0.05660377  1.         -0.88461538]\n",
      " [-0.05660377  1.         -0.15384615]\n",
      " [-0.05660377  0.63636364 -0.96153846]\n",
      " [-0.01886792  0.27272727 -0.65384615]\n",
      " [-0.01886792  0.45454545 -0.88461538]\n",
      " [-0.01886792 -0.63636364 -1.        ]\n",
      " [-0.01886792  0.45454545 -0.92307692]\n",
      " [-0.01886792  0.45454545 -0.96153846]\n",
      " [-0.01886792  0.63636364 -1.        ]\n",
      " [-0.01886792 -0.63636364 -1.        ]\n",
      " [ 0.01886792 -0.45454545 -0.80769231]\n",
      " [ 0.01886792 -0.27272727 -0.46153846]\n",
      " [ 0.01886792  0.09090909 -0.96153846]\n",
      " [ 0.01886792  0.09090909 -0.65384615]\n",
      " [ 0.01886792  1.         -1.        ]\n",
      " [ 0.01886792 -0.45454545 -1.        ]\n",
      " [ 0.01886792 -0.27272727 -1.        ]\n",
      " [ 0.01886792 -0.09090909 -1.        ]\n",
      " [ 0.01886792  0.09090909 -1.        ]\n",
      " [ 0.01886792  0.09090909 -1.        ]\n",
      " [ 0.01886792  0.63636364 -1.        ]\n",
      " [ 0.05660377 -0.81818182 -1.        ]\n",
      " [ 0.05660377 -0.63636364 -0.88461538]\n",
      " [ 0.05660377 -0.45454545 -0.96153846]\n",
      " [ 0.05660377  0.63636364 -1.        ]\n",
      " [ 0.05660377 -1.         -1.        ]\n",
      " [ 0.05660377 -1.         -0.88461538]\n",
      " [ 0.05660377 -0.45454545 -0.92307692]\n",
      " [ 0.09433962 -0.27272727  0.34615385]\n",
      " [ 0.09433962 -0.63636364 -1.        ]\n",
      " [ 0.09433962 -0.09090909 -1.        ]\n",
      " [ 0.09433962  0.09090909 -0.96153846]\n",
      " [ 0.09433962  0.09090909 -0.84615385]\n",
      " [ 0.09433962  0.09090909 -1.        ]\n",
      " [ 0.09433962  0.09090909 -0.73076923]\n",
      " [ 0.09433962  0.63636364 -0.88461538]\n",
      " [ 0.13207547 -0.81818182 -0.34615385]\n",
      " [ 0.13207547  0.27272727 -1.        ]\n",
      " [ 0.13207547 -0.45454545 -0.96153846]\n",
      " [ 0.13207547  0.63636364 -0.92307692]\n",
      " [ 0.13207547 -0.45454545 -0.03846154]\n",
      " [ 0.13207547  0.09090909 -1.        ]\n",
      " [ 0.16981132 -0.27272727 -0.80769231]\n",
      " [ 0.16981132  0.27272727 -1.        ]\n",
      " [ 0.16981132  0.81818182 -0.96153846]\n",
      " [ 0.16981132 -0.81818182 -1.        ]\n",
      " [ 0.16981132 -0.81818182 -1.        ]\n",
      " [ 0.16981132  0.09090909 -1.        ]\n",
      " [ 0.16981132  0.27272727 -0.69230769]\n",
      " [ 0.16981132  0.81818182 -1.        ]\n",
      " [ 0.16981132 -0.81818182 -1.        ]\n",
      " [ 0.20754717 -0.81818182 -0.5       ]\n",
      " [ 0.20754717 -1.         -1.        ]\n",
      " [ 0.20754717  0.27272727 -0.26923077]\n",
      " [ 0.20754717 -0.27272727 -0.76923077]\n",
      " [ 0.20754717  0.45454545 -1.        ]\n",
      " [ 0.20754717  0.45454545 -1.        ]\n",
      " [ 0.20754717 -1.         -1.        ]\n",
      " [ 0.24528302 -0.63636364 -0.96153846]\n",
      " [ 0.24528302 -0.45454545 -1.        ]\n",
      " [ 0.24528302 -0.27272727 -1.        ]\n",
      " [ 0.24528302 -0.09090909 -1.        ]\n",
      " [ 0.24528302 -0.09090909 -1.        ]\n",
      " [ 0.24528302  0.45454545 -1.        ]\n",
      " [ 0.24528302 -0.45454545 -0.65384615]\n",
      " [ 0.24528302 -0.45454545  0.07692308]\n",
      " [ 0.28301887 -1.         -1.        ]\n",
      " [ 0.28301887  0.27272727 -0.15384615]\n",
      " [ 0.28301887  0.45454545 -1.        ]\n",
      " [ 0.28301887 -0.45454545 -1.        ]\n",
      " [ 0.28301887  0.81818182 -1.        ]\n",
      " [ 0.32075472 -1.         -1.        ]\n",
      " [ 0.32075472 -0.45454545 -0.92307692]\n",
      " [ 0.32075472 -0.27272727 -0.15384615]\n",
      " [ 0.32075472  0.45454545 -0.42307692]\n",
      " [ 0.32075472 -1.         -1.        ]\n",
      " [ 0.32075472  0.09090909 -1.        ]\n",
      " [ 0.32075472  0.63636364 -1.        ]\n",
      " [ 0.32075472 -0.81818182 -0.92307692]\n",
      " [ 0.32075472  0.09090909 -1.        ]\n",
      " [ 0.32075472  0.63636364 -0.96153846]\n",
      " [ 0.35849057 -1.         -1.        ]\n",
      " [ 0.35849057 -0.45454545 -0.5       ]\n",
      " [ 0.35849057 -1.         -1.        ]\n",
      " [ 0.35849057 -1.         -0.96153846]\n",
      " [ 0.35849057  0.81818182 -1.        ]\n",
      " [ 0.39622642  0.09090909 -0.69230769]\n",
      " [ 0.39622642 -0.09090909 -0.96153846]\n",
      " [ 0.39622642  0.45454545 -1.        ]\n",
      " [ 0.39622642  0.45454545 -1.        ]\n",
      " [ 0.39622642 -0.45454545 -1.        ]\n",
      " [ 0.39622642  0.27272727 -1.        ]\n",
      " [ 0.43396226  0.63636364 -1.        ]\n",
      " [ 0.43396226  0.81818182 -1.        ]\n",
      " [ 0.47169811  0.63636364 -0.69230769]\n",
      " [ 0.47169811 -0.63636364 -1.        ]\n",
      " [ 0.47169811  0.27272727 -1.        ]\n",
      " [ 0.47169811  0.45454545 -1.        ]\n",
      " [ 0.50943396 -1.         -1.        ]\n",
      " [ 0.50943396 -1.         -0.84615385]\n",
      " [ 0.50943396  0.45454545 -0.46153846]\n",
      " [ 0.50943396  0.63636364 -1.        ]\n",
      " [ 0.50943396  0.81818182 -1.        ]\n",
      " [ 0.50943396 -0.81818182 -0.69230769]\n",
      " [ 0.50943396 -0.09090909 -1.        ]\n",
      " [ 0.54716981  0.81818182 -0.92307692]\n",
      " [ 0.58490566 -0.09090909 -1.        ]\n",
      " [ 0.58490566 -1.         -1.        ]\n",
      " [ 0.58490566  0.09090909 -1.        ]\n",
      " [ 0.58490566  0.63636364 -0.88461538]\n",
      " [ 0.62264151 -0.27272727 -1.        ]\n",
      " [ 0.62264151  0.81818182 -1.        ]\n",
      " [ 0.66037736  0.27272727 -0.88461538]\n",
      " [ 0.66037736 -0.09090909 -1.        ]\n",
      " [ 0.69811321 -0.27272727 -0.96153846]\n",
      " [ 0.73584906  0.63636364 -1.        ]\n",
      " [ 0.77358491  0.27272727 -0.88461538]\n",
      " [ 0.81132075  0.27272727 -0.96153846]\n",
      " [ 1.         -1.         -0.92307692]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ad1026858\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data to normalize data points and bring to same scale\n",
    "# using MinMaxScala brings all data point to range between -1 and 1\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "print('Preprocessed Features: ',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 2\n",
      " 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 2 2 1 1\n",
      " 1 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1\n",
      " 1 1 1 1 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 2 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 2 1 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "\n",
    "y = np.array(df['survival_status'])\n",
    "print('Labels: ',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since, we have three features, we require three slopes. One for each feature.\n",
    "\n",
    "So, the equation is like:\n",
    "\n",
    "#### y_hat = sigmoid(m1X1 + m2X2 + m3X3)\n",
    "\n",
    "Here, we will define the slope as an array and refer to them as follows:\n",
    "\n",
    "#### m = [0,0,0]\n",
    "\n",
    "#### m1:  m[0]\n",
    "\n",
    "#### m2: m[1]\n",
    "\n",
    "#### m3: m[2]\n",
    "\n",
    "Similarly for the values of X:\n",
    "\n",
    "#### 'age' : X[0]\n",
    "\n",
    "#### 'year_operation' : X[1]\n",
    "\n",
    "#### 'pos_auxillary_nodes' : X[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "# Initial Slopes [m1,m2,m3]\n",
    "initial_m = [0,0,0]\n",
    "\n",
    "# Learning Rate\n",
    "learning_Rate = 0.01\n",
    "\n",
    "# Number of Iterations\n",
    "iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  0.69314718056\n",
      "Initial Cost with m1 = 0, m2 = 0 and m3 = 0 is Cost = 0.6931471805599467\n"
     ]
    }
   ],
   "source": [
    "# Initial Cost\n",
    "\n",
    "print('Initial Cost with m1 = {0}, m2 = {1} and m3 = {2} is Cost = {3}'.format(initial_m[0],initial_m[1],initial_m[2],costFunction(X,y,initial_m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we have defined all the inputs, defined all the functions, it's time to test our classifier. So, let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  0.690300019945\n",
      "Cost:  0.690300019945\n",
      "m:  [-0.0010315496442932252, -0.00091654247391951681, -0.0061179066834804478]\n",
      "Cost:  0.690300019945\n",
      "Cost  0.690300019945\n",
      "\n",
      "\n",
      "Cost:  0.687467380957\n",
      "Cost:  0.684649197228\n",
      "Cost:  0.681845402404\n",
      "Cost:  0.679055930154\n",
      "Cost:  0.676280714174\n",
      "Cost:  0.673519688191\n",
      "Cost:  0.670772785969\n",
      "Cost:  0.668039941318\n",
      "Cost:  0.665321088094\n",
      "Cost:  0.662616160204\n",
      "Cost:  0.659925091618\n",
      "Cost:  0.657247816364\n",
      "Cost:  0.654584268541\n",
      "Cost:  0.65193438232\n",
      "Cost:  0.649298091949\n",
      "Cost:  0.646675331757\n",
      "Cost:  0.644066036161\n",
      "Cost:  0.641470139668\n",
      "Cost:  0.638887576882\n",
      "Cost:  0.636318282504\n",
      "Cost:  0.633762191341\n",
      "Cost:  0.631219238307\n",
      "Cost:  0.628689358428\n",
      "Cost:  0.626172486847\n",
      "Cost:  0.623668558827\n",
      "Cost:  0.621177509754\n",
      "Cost:  0.618699275143\n",
      "Cost:  0.616233790639\n",
      "Cost:  0.613780992024\n",
      "Cost:  0.611340815215\n",
      "Cost:  0.608913196277\n",
      "Cost:  0.606498071414\n",
      "Cost:  0.604095376985\n",
      "Cost:  0.601705049496\n",
      "Cost:  0.599327025612\n",
      "Cost:  0.596961242156\n",
      "Cost:  0.594607636112\n",
      "Cost:  0.592266144627\n",
      "Cost:  0.589936705019\n",
      "Cost:  0.587619254775\n",
      "Cost:  0.585313731555\n",
      "Cost:  0.583020073194\n",
      "Cost:  0.580738217708\n",
      "Cost:  0.578468103294\n",
      "Cost:  0.57620966833\n",
      "Cost:  0.573962851385\n",
      "Cost:  0.571727591212\n",
      "Cost:  0.569503826758\n",
      "Cost:  0.567291497164\n",
      "Cost:  0.565090541764\n",
      "Cost:  0.562900900092\n",
      "Cost:  0.560722511881\n",
      "Cost:  0.558555317066\n",
      "Cost:  0.556399255786\n",
      "Cost:  0.554254268387\n",
      "Cost:  0.552120295422\n",
      "Cost:  0.549997277652\n",
      "Cost:  0.547885156053\n",
      "Cost:  0.545783871811\n",
      "Cost:  0.543693366327\n",
      "Cost:  0.541613581221\n",
      "Cost:  0.539544458328\n",
      "Cost:  0.537485939704\n",
      "Cost:  0.535437967626\n",
      "Cost:  0.533400484591\n",
      "Cost:  0.531373433323\n",
      "Cost:  0.529356756769\n",
      "Cost:  0.527350398102\n",
      "Cost:  0.525354300722\n",
      "Cost:  0.523368408259\n",
      "Cost:  0.521392664572\n",
      "Cost:  0.519427013751\n",
      "Cost:  0.517471400115\n",
      "Cost:  0.51552576822\n",
      "Cost:  0.513590062852\n",
      "Cost:  0.511664229033\n",
      "Cost:  0.50974821202\n",
      "Cost:  0.507841957307\n",
      "Cost:  0.505945410622\n",
      "Cost:  0.504058517933\n",
      "Cost:  0.502181225446\n",
      "Cost:  0.500313479605\n",
      "Cost:  0.498455227094\n",
      "Cost:  0.496606414836\n",
      "Cost:  0.494766989995\n",
      "Cost:  0.492936899976\n",
      "Cost:  0.491116092425\n",
      "Cost:  0.489304515232\n",
      "Cost:  0.487502116525\n",
      "Cost:  0.485708844677\n",
      "Cost:  0.483924648305\n",
      "Cost:  0.482149476265\n",
      "Cost:  0.480383277661\n",
      "Cost:  0.478626001836\n",
      "Cost:  0.476877598381\n",
      "Cost:  0.475138017126\n",
      "Cost:  0.473407208149\n",
      "Cost:  0.47168512177\n",
      "Cost:  0.469971708553\n",
      "Cost:  0.468266919306\n",
      "Cost:  0.468266919306\n",
      "m:  [-0.093089869451238899, -0.081278353053880759, -0.55909123611318778]\n",
      "Cost:  0.468266919306\n",
      "Cost  0.468266919306\n",
      "\n",
      "\n",
      "Cost:  0.466570705081\n",
      "Cost:  0.464883017175\n",
      "Cost:  0.463203807127\n",
      "Cost:  0.461533026721\n",
      "Cost:  0.459870627985\n",
      "Cost:  0.458216563189\n",
      "Cost:  0.456570784848\n",
      "Cost:  0.454933245719\n",
      "Cost:  0.453303898802\n",
      "Cost:  0.451682697341\n",
      "Cost:  0.45006959482\n",
      "Cost:  0.448464544967\n",
      "Cost:  0.446867501751\n",
      "Cost:  0.445278419384\n",
      "Cost:  0.443697252317\n",
      "Cost:  0.442123955242\n",
      "Cost:  0.440558483093\n",
      "Cost:  0.439000791043\n",
      "Cost:  0.437450834504\n",
      "Cost:  0.435908569127\n",
      "Cost:  0.434373950803\n",
      "Cost:  0.43284693566\n",
      "Cost:  0.431327480063\n",
      "Cost:  0.429815540616\n",
      "Cost:  0.428311074158\n",
      "Cost:  0.426814037764\n",
      "Cost:  0.425324388744\n",
      "Cost:  0.423842084646\n",
      "Cost:  0.422367083247\n",
      "Cost:  0.420899342562\n",
      "Cost:  0.419438820837\n",
      "Cost:  0.417985476551\n",
      "Cost:  0.416539268413\n",
      "Cost:  0.415100155366\n",
      "Cost:  0.413668096581\n",
      "Cost:  0.412243051459\n",
      "Cost:  0.410824979631\n",
      "Cost:  0.409413840954\n",
      "Cost:  0.408009595515\n",
      "Cost:  0.406612203626\n",
      "Cost:  0.405221625826\n",
      "Cost:  0.403837822878\n",
      "Cost:  0.402460755771\n",
      "Cost:  0.401090385716\n",
      "Cost:  0.399726674148\n",
      "Cost:  0.398369582724\n",
      "Cost:  0.397019073322\n",
      "Cost:  0.39567510804\n",
      "Cost:  0.394337649197\n",
      "Cost:  0.393006659328\n",
      "Cost:  0.391682101189\n",
      "Cost:  0.390363937752\n",
      "Cost:  0.389052132204\n",
      "Cost:  0.38774664795\n",
      "Cost:  0.386447448607\n",
      "Cost:  0.385154498006\n",
      "Cost:  0.383867760193\n",
      "Cost:  0.382587199422\n",
      "Cost:  0.381312780163\n",
      "Cost:  0.38004446709\n",
      "Cost:  0.378782225092\n",
      "Cost:  0.377526019262\n",
      "Cost:  0.376275814904\n",
      "Cost:  0.375031577524\n",
      "Cost:  0.373793272838\n",
      "Cost:  0.372560866763\n",
      "Cost:  0.371334325423\n",
      "Cost:  0.370113615142\n",
      "Cost:  0.368898702446\n",
      "Cost:  0.367689554065\n",
      "Cost:  0.366486136924\n",
      "Cost:  0.365288418152\n",
      "Cost:  0.364096365072\n",
      "Cost:  0.362909945206\n",
      "Cost:  0.361729126272\n",
      "Cost:  0.360553876184\n",
      "Cost:  0.359384163048\n",
      "Cost:  0.358219955165\n",
      "Cost:  0.357061221028\n",
      "Cost:  0.355907929322\n",
      "Cost:  0.354760048922\n",
      "Cost:  0.35361754889\n",
      "Cost:  0.352480398481\n",
      "Cost:  0.351348567134\n",
      "Cost:  0.350222024477\n",
      "Cost:  0.349100740321\n",
      "Cost:  0.347984684664\n",
      "Cost:  0.346873827686\n",
      "Cost:  0.345768139752\n",
      "Cost:  0.344667591405\n",
      "Cost:  0.343572153373\n",
      "Cost:  0.342481796561\n",
      "Cost:  0.341396492054\n",
      "Cost:  0.340316211115\n",
      "Cost:  0.339240925183\n",
      "Cost:  0.338170605874\n",
      "Cost:  0.337105224979\n",
      "Cost:  0.336044754462\n",
      "Cost:  0.334989166462\n",
      "Cost:  0.333938433288\n",
      "Cost:  0.333938433288\n",
      "m:  [-0.16743117358122858, -0.14408584967925839, -1.0163193296036088]\n",
      "Cost:  0.333938433288\n",
      "Cost  0.333938433288\n",
      "\n",
      "\n",
      "Cost:  0.332892527421\n",
      "Cost:  0.331851421514\n",
      "Cost:  0.330815088387\n",
      "Cost:  0.32978350103\n",
      "Cost:  0.328756632599\n",
      "Cost:  0.327734456416\n",
      "Cost:  0.326716945972\n",
      "Cost:  0.325704074919\n",
      "Cost:  0.324695817075\n",
      "Cost:  0.323692146418\n",
      "Cost:  0.32269303709\n",
      "Cost:  0.321698463394\n",
      "Cost:  0.320708399792\n",
      "Cost:  0.319722820905\n",
      "Cost:  0.318741701511\n",
      "Cost:  0.317765016549\n",
      "Cost:  0.31679274111\n",
      "Cost:  0.315824850442\n",
      "Cost:  0.314861319947\n",
      "Cost:  0.313902125182\n",
      "Cost:  0.312947241855\n",
      "Cost:  0.311996645825\n",
      "Cost:  0.311050313104\n",
      "Cost:  0.310108219853\n",
      "Cost:  0.30917034238\n",
      "Cost:  0.308236657143\n",
      "Cost:  0.307307140748\n",
      "Cost:  0.306381769945\n",
      "Cost:  0.305460521632\n",
      "Cost:  0.304543372849\n",
      "Cost:  0.30363030078\n",
      "Cost:  0.302721282754\n",
      "Cost:  0.30181629624\n",
      "Cost:  0.300915318848\n",
      "Cost:  0.300018328329\n",
      "Cost:  0.299125302573\n",
      "Cost:  0.298236219608\n",
      "Cost:  0.297351057599\n",
      "Cost:  0.296469794851\n",
      "Cost:  0.2955924098\n",
      "Cost:  0.294718881022\n",
      "Cost:  0.293849187223\n",
      "Cost:  0.292983307245\n",
      "Cost:  0.292121220062\n",
      "Cost:  0.291262904779\n",
      "Cost:  0.290408340633\n",
      "Cost:  0.28955750699\n",
      "Cost:  0.288710383345\n",
      "Cost:  0.287866949324\n",
      "Cost:  0.287027184677\n",
      "Cost:  0.286191069283\n",
      "Cost:  0.285358583148\n",
      "Cost:  0.2845297064\n",
      "Cost:  0.283704419294\n",
      "Cost:  0.282882702208\n",
      "Cost:  0.282064535642\n",
      "Cost:  0.281249900221\n",
      "Cost:  0.280438776687\n",
      "Cost:  0.279631145905\n",
      "Cost:  0.278826988861\n",
      "Cost:  0.278026286656\n",
      "Cost:  0.277229020514\n",
      "Cost:  0.276435171772\n",
      "Cost:  0.275644721887\n",
      "Cost:  0.274857652431\n",
      "Cost:  0.27407394509\n",
      "Cost:  0.273293581666\n",
      "Cost:  0.272516544073\n",
      "Cost:  0.271742814341\n",
      "Cost:  0.27097237461\n",
      "Cost:  0.270205207131\n",
      "Cost:  0.269441294267\n",
      "Cost:  0.268680618491\n",
      "Cost:  0.267923162385\n",
      "Cost:  0.26716890864\n",
      "Cost:  0.266417840055\n",
      "Cost:  0.265669939536\n",
      "Cost:  0.264925190096\n",
      "Cost:  0.264183574853\n",
      "Cost:  0.26344507703\n",
      "Cost:  0.262709679956\n",
      "Cost:  0.261977367063\n",
      "Cost:  0.261248121886\n",
      "Cost:  0.260521928063\n",
      "Cost:  0.259798769332\n",
      "Cost:  0.259078629534\n",
      "Cost:  0.258361492609\n",
      "Cost:  0.257647342599\n",
      "Cost:  0.256936163643\n",
      "Cost:  0.25622793998\n",
      "Cost:  0.255522655944\n",
      "Cost:  0.25482029597\n",
      "Cost:  0.254120844587\n",
      "Cost:  0.253424286421\n",
      "Cost:  0.252730606192\n",
      "Cost:  0.252039788716\n",
      "Cost:  0.251351818903\n",
      "Cost:  0.250666681756\n",
      "Cost:  0.24998436237\n",
      "Cost:  0.249304845933\n",
      "Cost:  0.249304845933\n",
      "m:  [-0.22968201947224232, -0.19560829933914509, -1.4053548228945918]\n",
      "Cost:  0.249304845933\n",
      "Cost  0.249304845933\n",
      "\n",
      "\n",
      "Cost:  0.248628117724\n",
      "Cost:  0.247954163114\n",
      "Cost:  0.247282967563\n",
      "Cost:  0.246614516623\n",
      "Cost:  0.245948795931\n",
      "Cost:  0.245285791218\n",
      "Cost:  0.244625488298\n",
      "Cost:  0.243967873075\n",
      "Cost:  0.243312931539\n",
      "Cost:  0.242660649768\n",
      "Cost:  0.242011013922\n",
      "Cost:  0.24136401025\n",
      "Cost:  0.240719625083\n",
      "Cost:  0.240077844836\n",
      "Cost:  0.239438656009\n",
      "Cost:  0.238802045184\n",
      "Cost:  0.238167999025\n",
      "Cost:  0.237536504278\n",
      "Cost:  0.23690754777\n",
      "Cost:  0.236281116409\n",
      "Cost:  0.235657197182\n",
      "Cost:  0.235035777158\n",
      "Cost:  0.234416843483\n",
      "Cost:  0.233800383383\n",
      "Cost:  0.233186384159\n",
      "Cost:  0.232574833193\n",
      "Cost:  0.231965717942\n",
      "Cost:  0.231359025941\n",
      "Cost:  0.230754744799\n",
      "Cost:  0.230152862202\n",
      "Cost:  0.229553365909\n",
      "Cost:  0.228956243757\n",
      "Cost:  0.228361483652\n",
      "Cost:  0.227769073579\n",
      "Cost:  0.22717900159\n",
      "Cost:  0.226591255815\n",
      "Cost:  0.226005824453\n",
      "Cost:  0.225422695774\n",
      "Cost:  0.224841858121\n",
      "Cost:  0.224263299906\n",
      "Cost:  0.223687009612\n",
      "Cost:  0.223112975792\n",
      "Cost:  0.222541187066\n",
      "Cost:  0.221971632124\n",
      "Cost:  0.221404299726\n",
      "Cost:  0.220839178697\n",
      "Cost:  0.22027625793\n",
      "Cost:  0.219715526386\n",
      "Cost:  0.219156973092\n",
      "Cost:  0.218600587139\n",
      "Cost:  0.218046357688\n",
      "Cost:  0.217494273959\n",
      "Cost:  0.216944325243\n",
      "Cost:  0.21639650089\n",
      "Cost:  0.215850790317\n",
      "Cost:  0.215307183003\n",
      "Cost:  0.214765668491\n",
      "Cost:  0.214226236385\n",
      "Cost:  0.213688876353\n",
      "Cost:  0.213153578123\n",
      "Cost:  0.212620331485\n",
      "Cost:  0.21208912629\n",
      "Cost:  0.21155995245\n",
      "Cost:  0.211032799935\n",
      "Cost:  0.210507658777\n",
      "Cost:  0.209984519067\n",
      "Cost:  0.209463370954\n",
      "Cost:  0.208944204644\n",
      "Cost:  0.208427010406\n",
      "Cost:  0.207911778561\n",
      "Cost:  0.207398499491\n",
      "Cost:  0.206887163634\n",
      "Cost:  0.206377761484\n",
      "Cost:  0.205870283592\n",
      "Cost:  0.205364720564\n",
      "Cost:  0.204861063063\n",
      "Cost:  0.204359301805\n",
      "Cost:  0.203859427562\n",
      "Cost:  0.203361431161\n",
      "Cost:  0.20286530348\n",
      "Cost:  0.202371035455\n",
      "Cost:  0.201878618072\n",
      "Cost:  0.201388042371\n",
      "Cost:  0.200899299445\n",
      "Cost:  0.200412380438\n",
      "Cost:  0.199927276546\n",
      "Cost:  0.19944397902\n",
      "Cost:  0.198962479156\n",
      "Cost:  0.198482768307\n",
      "Cost:  0.198004837872\n",
      "Cost:  0.197528679302\n",
      "Cost:  0.197054284099\n",
      "Cost:  0.196581643812\n",
      "Cost:  0.196110750042\n",
      "Cost:  0.195641594437\n",
      "Cost:  0.195174168693\n",
      "Cost:  0.194708464556\n",
      "Cost:  0.194244473819\n",
      "Cost:  0.193782188323\n",
      "Cost:  0.193321599955\n",
      "Cost:  0.193321599955\n",
      "m:  [-0.28380664489980933, -0.24009666678264541, -1.7462913478102904]\n",
      "Cost:  0.193321599955\n",
      "Cost  0.193321599955\n",
      "\n",
      "\n",
      "Cost:  0.192862700652\n",
      "Cost:  0.192405482394\n",
      "Cost:  0.191949937209\n",
      "Cost:  0.191496057172\n",
      "Cost:  0.191043834402\n",
      "Cost:  0.190593261065\n",
      "Cost:  0.19014432937\n",
      "Cost:  0.189697031575\n",
      "Cost:  0.189251359977\n",
      "Cost:  0.188807306922\n",
      "Cost:  0.188364864797\n",
      "Cost:  0.187924026035\n",
      "Cost:  0.18748478311\n",
      "Cost:  0.18704712854\n",
      "Cost:  0.186611054888\n",
      "Cost:  0.186176554756\n",
      "Cost:  0.185743620791\n",
      "Cost:  0.18531224568\n",
      "Cost:  0.184882422154\n",
      "Cost:  0.184454142983\n",
      "Cost:  0.18402740098\n",
      "Cost:  0.183602188998\n",
      "Cost:  0.183178499932\n",
      "Cost:  0.182756326714\n",
      "Cost:  0.182335662321\n",
      "Cost:  0.181916499765\n",
      "Cost:  0.181498832101\n",
      "Cost:  0.181082652423\n",
      "Cost:  0.180667953862\n",
      "Cost:  0.18025472959\n",
      "Cost:  0.179842972817\n",
      "Cost:  0.17943267679\n",
      "Cost:  0.179023834796\n",
      "Cost:  0.178616440158\n",
      "Cost:  0.178210486239\n",
      "Cost:  0.177805966437\n",
      "Cost:  0.177402874188\n",
      "Cost:  0.177001202965\n",
      "Cost:  0.176600946278\n",
      "Cost:  0.176202097673\n",
      "Cost:  0.175804650732\n",
      "Cost:  0.175408599072\n",
      "Cost:  0.175013936347\n",
      "Cost:  0.174620656248\n",
      "Cost:  0.174228752497\n",
      "Cost:  0.173838218854\n",
      "Cost:  0.173449049114\n",
      "Cost:  0.173061237106\n",
      "Cost:  0.172674776691\n",
      "Cost:  0.172289661768\n",
      "Cost:  0.171905886268\n",
      "Cost:  0.171523444154\n",
      "Cost:  0.171142329427\n",
      "Cost:  0.170762536116\n",
      "Cost:  0.170384058287\n",
      "Cost:  0.170006890036\n",
      "Cost:  0.169631025494\n",
      "Cost:  0.169256458823\n",
      "Cost:  0.168883184218\n",
      "Cost:  0.168511195905\n",
      "Cost:  0.168140488142\n",
      "Cost:  0.167771055219\n",
      "Cost:  0.167402891457\n",
      "Cost:  0.16703599121\n",
      "Cost:  0.166670348859\n",
      "Cost:  0.166305958821\n",
      "Cost:  0.165942815538\n",
      "Cost:  0.165580913487\n",
      "Cost:  0.165220247173\n",
      "Cost:  0.164860811132\n",
      "Cost:  0.164502599928\n",
      "Cost:  0.164145608157\n",
      "Cost:  0.163789830442\n",
      "Cost:  0.163435261438\n",
      "Cost:  0.163081895826\n",
      "Cost:  0.16272972832\n",
      "Cost:  0.162378753658\n",
      "Cost:  0.16202896661\n",
      "Cost:  0.161680361972\n",
      "Cost:  0.16133293457\n",
      "Cost:  0.160986679258\n",
      "Cost:  0.160641590916\n",
      "Cost:  0.160297664453\n",
      "Cost:  0.159954894805\n",
      "Cost:  0.159613276937\n",
      "Cost:  0.159272805837\n",
      "Cost:  0.158933476524\n",
      "Cost:  0.158595284043\n",
      "Cost:  0.158258223464\n",
      "Cost:  0.157922289884\n",
      "Cost:  0.157587478428\n",
      "Cost:  0.157253784244\n",
      "Cost:  0.15692120251\n",
      "Cost:  0.156589728426\n",
      "Cost:  0.156259357219\n",
      "Cost:  0.155930084142\n",
      "Cost:  0.155601904474\n",
      "Cost:  0.155274813517\n",
      "Cost:  0.154948806599\n",
      "Cost:  0.154623879073\n",
      "Cost:  0.154623879073\n",
      "m:  [-0.33236910549246257, -0.28016702368536667, -2.0527495683650421]\n",
      "Cost:  0.154623879073\n",
      "Cost  0.154623879073\n",
      "\n",
      "\n",
      "Cost:  0.154300026317\n",
      "Cost:  0.153977243734\n",
      "Cost:  0.153655526749\n",
      "Cost:  0.153334870813\n",
      "Cost:  0.153015271401\n",
      "Cost:  0.152696724013\n",
      "Cost:  0.15237922417\n",
      "Cost:  0.152062767419\n",
      "Cost:  0.15174734933\n",
      "Cost:  0.151432965495\n",
      "Cost:  0.15111961153\n",
      "Cost:  0.150807283076\n",
      "Cost:  0.150495975795\n",
      "Cost:  0.15018568537\n",
      "Cost:  0.149876407511\n",
      "Cost:  0.149568137947\n",
      "Cost:  0.14926087243\n",
      "Cost:  0.148954606736\n",
      "Cost:  0.14864933666\n",
      "Cost:  0.148345058023\n",
      "Cost:  0.148041766664\n",
      "Cost:  0.147739458445\n",
      "Cost:  0.147438129251\n",
      "Cost:  0.147137774986\n",
      "Cost:  0.146838391577\n",
      "Cost:  0.146539974972\n",
      "Cost:  0.146242521139\n",
      "Cost:  0.145946026068\n",
      "Cost:  0.145650485769\n",
      "Cost:  0.145355896273\n",
      "Cost:  0.145062253632\n",
      "Cost:  0.144769553917\n",
      "Cost:  0.144477793221\n",
      "Cost:  0.144186967656\n",
      "Cost:  0.143897073354\n",
      "Cost:  0.143608106467\n",
      "Cost:  0.143320063168\n",
      "Cost:  0.143032939648\n",
      "Cost:  0.142746732118\n",
      "Cost:  0.142461436809\n",
      "Cost:  0.142177049971\n",
      "Cost:  0.141893567873\n",
      "Cost:  0.141610986803\n",
      "Cost:  0.141329303068\n",
      "Cost:  0.141048512995\n",
      "Cost:  0.140768612928\n",
      "Cost:  0.140489599231\n",
      "Cost:  0.140211468285\n",
      "Cost:  0.13993421649\n",
      "Cost:  0.139657840266\n",
      "Cost:  0.139382336049\n",
      "Cost:  0.139107700293\n",
      "Cost:  0.138833929472\n",
      "Cost:  0.138561020076\n",
      "Cost:  0.138288968614\n",
      "Cost:  0.138017771611\n",
      "Cost:  0.137747425612\n",
      "Cost:  0.137477927176\n",
      "Cost:  0.137209272883\n",
      "Cost:  0.136941459327\n",
      "Cost:  0.136674483123\n",
      "Cost:  0.136408340898\n",
      "Cost:  0.1361430293\n",
      "Cost:  0.135878544993\n",
      "Cost:  0.135614884656\n",
      "Cost:  0.135352044986\n",
      "Cost:  0.135090022697\n",
      "Cost:  0.134828814517\n",
      "Cost:  0.134568417194\n",
      "Cost:  0.134308827489\n",
      "Cost:  0.134050042181\n",
      "Cost:  0.133792058064\n",
      "Cost:  0.133534871948\n",
      "Cost:  0.133278480661\n",
      "Cost:  0.133022881043\n",
      "Cost:  0.132768069953\n",
      "Cost:  0.132514044263\n",
      "Cost:  0.132260800862\n",
      "Cost:  0.132008336655\n",
      "Cost:  0.131756648561\n",
      "Cost:  0.131505733514\n",
      "Cost:  0.131255588465\n",
      "Cost:  0.131006210377\n",
      "Cost:  0.130757596231\n",
      "Cost:  0.130509743021\n",
      "Cost:  0.130262647757\n",
      "Cost:  0.130016307462\n",
      "Cost:  0.129770719176\n",
      "Cost:  0.12952587995\n",
      "Cost:  0.129281786854\n",
      "Cost:  0.129038436968\n",
      "Cost:  0.128795827389\n",
      "Cost:  0.128553955228\n",
      "Cost:  0.128312817608\n",
      "Cost:  0.128072411669\n",
      "Cost:  0.127832734563\n",
      "Cost:  0.127593783455\n",
      "Cost:  0.127355555526\n",
      "Cost:  0.12711804797\n",
      "Cost:  0.126881257995\n",
      "Cost:  0.126881257995\n",
      "m:  [-0.37701796825349537, -0.31741311097061392, -2.3339194324003705]\n",
      "Cost:  0.126881257995\n",
      "Cost  0.126881257995\n",
      "\n",
      "\n",
      "Cost:  0.12664518282\n",
      "Cost:  0.12640981968\n",
      "Cost:  0.126175165824\n",
      "Cost:  0.125941218512\n",
      "Cost:  0.125707975018\n",
      "Cost:  0.12547543263\n",
      "Cost:  0.125243588648\n",
      "Cost:  0.125012440387\n",
      "Cost:  0.124781985171\n",
      "Cost:  0.124552220342\n",
      "Cost:  0.124323143249\n",
      "Cost:  0.12409475126\n",
      "Cost:  0.12386704175\n",
      "Cost:  0.12364001211\n",
      "Cost:  0.123413659743\n",
      "Cost:  0.123187982062\n",
      "Cost:  0.122962976496\n",
      "Cost:  0.122738640485\n",
      "Cost:  0.122514971479\n",
      "Cost:  0.122291966942\n",
      "Cost:  0.122069624351\n",
      "Cost:  0.121847941194\n",
      "Cost:  0.12162691497\n",
      "Cost:  0.121406543192\n",
      "Cost:  0.121186823382\n",
      "Cost:  0.120967753076\n",
      "Cost:  0.120749329821\n",
      "Cost:  0.120531551176\n",
      "Cost:  0.12031441471\n",
      "Cost:  0.120097918006\n",
      "Cost:  0.119882058656\n",
      "Cost:  0.119666834264\n",
      "Cost:  0.119452242446\n",
      "Cost:  0.11923828083\n",
      "Cost:  0.119024947052\n",
      "Cost:  0.118812238763\n",
      "Cost:  0.118600153621\n",
      "Cost:  0.118388689299\n",
      "Cost:  0.118177843477\n",
      "Cost:  0.11796761385\n",
      "Cost:  0.11775799812\n",
      "Cost:  0.117548994002\n",
      "Cost:  0.117340599221\n",
      "Cost:  0.117132811512\n",
      "Cost:  0.116925628622\n",
      "Cost:  0.116719048306\n",
      "Cost:  0.116513068333\n",
      "Cost:  0.11630768648\n",
      "Cost:  0.116102900533\n",
      "Cost:  0.115898708293\n",
      "Cost:  0.115695107565\n",
      "Cost:  0.11549209617\n",
      "Cost:  0.115289671934\n",
      "Cost:  0.115087832697\n",
      "Cost:  0.114886576308\n",
      "Cost:  0.114685900624\n",
      "Cost:  0.114485803513\n",
      "Cost:  0.114286282854\n",
      "Cost:  0.114087336535\n",
      "Cost:  0.113888962453\n",
      "Cost:  0.113691158514\n",
      "Cost:  0.113493922637\n",
      "Cost:  0.113297252746\n",
      "Cost:  0.113101146779\n",
      "Cost:  0.112905602679\n",
      "Cost:  0.112710618402\n",
      "Cost:  0.112516191912\n",
      "Cost:  0.112322321182\n",
      "Cost:  0.112129004194\n",
      "Cost:  0.11193623894\n",
      "Cost:  0.11174402342\n",
      "Cost:  0.111552355645\n",
      "Cost:  0.111361233634\n",
      "Cost:  0.111170655414\n",
      "Cost:  0.110980619023\n",
      "Cost:  0.110791122505\n",
      "Cost:  0.110602163916\n",
      "Cost:  0.110413741319\n",
      "Cost:  0.110225852785\n",
      "Cost:  0.110038496397\n",
      "Cost:  0.109851670243\n",
      "Cost:  0.109665372421\n",
      "Cost:  0.109479601038\n",
      "Cost:  0.109294354209\n",
      "Cost:  0.109109630058\n",
      "Cost:  0.108925426717\n",
      "Cost:  0.108741742326\n",
      "Cost:  0.108558575034\n",
      "Cost:  0.108375922997\n",
      "Cost:  0.108193784382\n",
      "Cost:  0.108012157362\n",
      "Cost:  0.107831040117\n",
      "Cost:  0.107650430839\n",
      "Cost:  0.107470327724\n",
      "Cost:  0.107290728979\n",
      "Cost:  0.107111632817\n",
      "Cost:  0.106933037461\n",
      "Cost:  0.106754941139\n",
      "Cost:  0.106577342089\n",
      "Cost:  0.106400238557\n",
      "Cost:  0.106400238557\n",
      "m:  [-0.41883541490829002, -0.35282434655123129, -2.5961165802397921]\n",
      "Cost:  0.106400238557\n",
      "Cost  0.106400238557\n",
      "\n",
      "\n",
      "Cost:  0.106223628795\n",
      "Cost:  0.106047511065\n",
      "Cost:  0.105871883635\n",
      "Cost:  0.105696744781\n",
      "Cost:  0.105522092786\n",
      "Cost:  0.105347925943\n",
      "Cost:  0.105174242549\n",
      "Cost:  0.105001040912\n",
      "Cost:  0.104828319344\n",
      "Cost:  0.104656076168\n",
      "Cost:  0.104484309711\n",
      "Cost:  0.10431301831\n",
      "Cost:  0.104142200308\n",
      "Cost:  0.103971854055\n",
      "Cost:  0.103801977909\n",
      "Cost:  0.103632570235\n",
      "Cost:  0.103463629404\n",
      "Cost:  0.103295153795\n",
      "Cost:  0.103127141796\n",
      "Cost:  0.102959591798\n",
      "Cost:  0.102792502202\n",
      "Cost:  0.102625871416\n",
      "Cost:  0.102459697853\n",
      "Cost:  0.102293979933\n",
      "Cost:  0.102128716086\n",
      "Cost:  0.101963904745\n",
      "Cost:  0.101799544351\n",
      "Cost:  0.101635633354\n",
      "Cost:  0.101472170207\n",
      "Cost:  0.101309153371\n",
      "Cost:  0.101146581316\n",
      "Cost:  0.100984452516\n",
      "Cost:  0.100822765451\n",
      "Cost:  0.100661518611\n",
      "Cost:  0.100500710488\n",
      "Cost:  0.100340339584\n",
      "Cost:  0.100180404406\n",
      "Cost:  0.100020903467\n",
      "Cost:  0.0998618352882\n",
      "Cost:  0.0997031983949\n",
      "Cost:  0.0995449913198\n",
      "Cost:  0.0993872126018\n",
      "Cost:  0.0992298607861\n",
      "Cost:  0.0990729344238\n",
      "Cost:  0.0989164320725\n",
      "Cost:  0.0987603522957\n",
      "Cost:  0.0986046936632\n",
      "Cost:  0.0984494547506\n",
      "Cost:  0.0982946341399\n",
      "Cost:  0.0981402304189\n",
      "Cost:  0.0979862421814\n",
      "Cost:  0.0978326680271\n",
      "Cost:  0.0976795065619\n",
      "Cost:  0.0975267563973\n",
      "Cost:  0.0973744161507\n",
      "Cost:  0.0972224844454\n",
      "Cost:  0.0970709599106\n",
      "Cost:  0.0969198411812\n",
      "Cost:  0.0967691268976\n",
      "Cost:  0.0966188157064\n",
      "Cost:  0.0964689062594\n",
      "Cost:  0.0963193972145\n",
      "Cost:  0.0961702872349\n",
      "Cost:  0.0960215749894\n",
      "Cost:  0.0958732591527\n",
      "Cost:  0.0957253384048\n",
      "Cost:  0.0955778114311\n",
      "Cost:  0.0954306769228\n",
      "Cost:  0.0952839335763\n",
      "Cost:  0.0951375800936\n",
      "Cost:  0.094991615182\n",
      "Cost:  0.0948460375542\n",
      "Cost:  0.0947008459284\n",
      "Cost:  0.0945560390279\n",
      "Cost:  0.0944116155814\n",
      "Cost:  0.0942675743229\n",
      "Cost:  0.0941239139917\n",
      "Cost:  0.0939806333321\n",
      "Cost:  0.0938377310938\n",
      "Cost:  0.0936952060317\n",
      "Cost:  0.0935530569056\n",
      "Cost:  0.0934112824806\n",
      "Cost:  0.0932698815269\n",
      "Cost:  0.0931288528197\n",
      "Cost:  0.0929881951392\n",
      "Cost:  0.0928479072709\n",
      "Cost:  0.0927079880048\n",
      "Cost:  0.0925684361363\n",
      "Cost:  0.0924292504655\n",
      "Cost:  0.0922904297976\n",
      "Cost:  0.0921519729424\n",
      "Cost:  0.092013878715\n",
      "Cost:  0.0918761459349\n",
      "Cost:  0.0917387734267\n",
      "Cost:  0.0916017600198\n",
      "Cost:  0.0914651045482\n",
      "Cost:  0.0913288058507\n",
      "Cost:  0.091192862771\n",
      "Cost:  0.0910572741573\n",
      "Cost:  0.0909220388626\n",
      "Cost:  0.0909220388626\n",
      "m:  [-0.4585519061397923, -0.38703129167472822, -2.843789327705267]\n",
      "Cost:  0.0909220388626\n",
      "Cost  0.0909220388626\n",
      "\n",
      "\n",
      "Cost:  0.0907871557444\n",
      "Cost:  0.0906526236651\n",
      "Cost:  0.0905184414914\n",
      "Cost:  0.0903846080949\n",
      "Cost:  0.0902511223515\n",
      "Cost:  0.0901179831419\n",
      "Cost:  0.089985189351\n",
      "Cost:  0.0898527398685\n",
      "Cost:  0.0897206335885\n",
      "Cost:  0.0895888694093\n",
      "Cost:  0.0894574462341\n",
      "Cost:  0.0893263629702\n",
      "Cost:  0.0891956185293\n",
      "Cost:  0.0890652118276\n",
      "Cost:  0.0889351417854\n",
      "Cost:  0.0888054073278\n",
      "Cost:  0.0886760073836\n",
      "Cost:  0.0885469408864\n",
      "Cost:  0.0884182067739\n",
      "Cost:  0.0882898039878\n",
      "Cost:  0.0881617314744\n",
      "Cost:  0.0880339881841\n",
      "Cost:  0.0879065730712\n",
      "Cost:  0.0877794850945\n",
      "Cost:  0.0876527232169\n",
      "Cost:  0.0875262864053\n",
      "Cost:  0.0874001736307\n",
      "Cost:  0.0872743838683\n",
      "Cost:  0.0871489160973\n",
      "Cost:  0.087023769301\n",
      "Cost:  0.0868989424666\n",
      "Cost:  0.0867744345854\n",
      "Cost:  0.0866502446527\n",
      "Cost:  0.0865263716678\n",
      "Cost:  0.0864028146337\n",
      "Cost:  0.0862795725577\n",
      "Cost:  0.0861566444508\n",
      "Cost:  0.0860340293279\n",
      "Cost:  0.0859117262077\n",
      "Cost:  0.085789734113\n",
      "Cost:  0.0856680520703\n",
      "Cost:  0.0855466791098\n",
      "Cost:  0.0854256142658\n",
      "Cost:  0.085304856576\n",
      "Cost:  0.0851844050821\n",
      "Cost:  0.0850642588296\n",
      "Cost:  0.0849444168676\n",
      "Cost:  0.084824878249\n",
      "Cost:  0.0847056420302\n",
      "Cost:  0.0845867072717\n",
      "Cost:  0.0844680730371\n",
      "Cost:  0.0843497383941\n",
      "Cost:  0.0842317024138\n",
      "Cost:  0.0841139641709\n",
      "Cost:  0.0839965227439\n",
      "Cost:  0.0838793772147\n",
      "Cost:  0.0837625266687\n",
      "Cost:  0.083645970195\n",
      "Cost:  0.0835297068862\n",
      "Cost:  0.0834137358382\n",
      "Cost:  0.0832980561508\n",
      "Cost:  0.0831826669268\n",
      "Cost:  0.0830675672728\n",
      "Cost:  0.0829527562987\n",
      "Cost:  0.0828382331179\n",
      "Cost:  0.0827239968472\n",
      "Cost:  0.0826100466067\n",
      "Cost:  0.0824963815199\n",
      "Cost:  0.0823830007138\n",
      "Cost:  0.0822699033187\n",
      "Cost:  0.0821570884681\n",
      "Cost:  0.082044555299\n",
      "Cost:  0.0819323029515\n",
      "Cost:  0.0818203305691\n",
      "Cost:  0.0817086372987\n",
      "Cost:  0.0815972222902\n",
      "Cost:  0.0814860846969\n",
      "Cost:  0.0813752236753\n",
      "Cost:  0.0812646383851\n",
      "Cost:  0.0811543279892\n",
      "Cost:  0.0810442916537\n",
      "Cost:  0.0809345285478\n",
      "Cost:  0.080825037844\n",
      "Cost:  0.0807158187177\n",
      "Cost:  0.0806068703477\n",
      "Cost:  0.0804981919156\n",
      "Cost:  0.0803897826064\n",
      "Cost:  0.0802816416081\n",
      "Cost:  0.0801737681116\n",
      "Cost:  0.0800661613109\n",
      "Cost:  0.0799588204033\n",
      "Cost:  0.0798517445888\n",
      "Cost:  0.0797449330706\n",
      "Cost:  0.0796383850548\n",
      "Cost:  0.0795320997505\n",
      "Cost:  0.0794260763699\n",
      "Cost:  0.0793203141279\n",
      "Cost:  0.0792148122426\n",
      "Cost:  0.0791095699349\n",
      "Cost:  0.0790045864287\n",
      "Cost:  0.0790045864287\n",
      "m:  [-0.49667441805876278, -0.42044617910495707, -3.0801487379861765]\n",
      "Cost:  0.0790045864287\n",
      "Cost  0.0790045864287\n",
      "\n",
      "\n",
      "Cost:  0.0788998609506\n",
      "Cost:  0.0787953927303\n",
      "Cost:  0.0786911810003\n",
      "Cost:  0.078587224996\n",
      "Cost:  0.0784835239556\n",
      "Cost:  0.0783800771202\n",
      "Cost:  0.0782768837337\n",
      "Cost:  0.0781739430427\n",
      "Cost:  0.0780712542968\n",
      "Cost:  0.0779688167482\n",
      "Cost:  0.077866629652\n",
      "Cost:  0.0777646922661\n",
      "Cost:  0.0776630038509\n",
      "Cost:  0.0775615636699\n",
      "Cost:  0.0774603709891\n",
      "Cost:  0.0773594250771\n",
      "Cost:  0.0772587252055\n",
      "Cost:  0.0771582706484\n",
      "Cost:  0.0770580606826\n",
      "Cost:  0.0769580945876\n",
      "Cost:  0.0768583716456\n",
      "Cost:  0.0767588911412\n",
      "Cost:  0.076659652362\n",
      "Cost:  0.0765606545978\n",
      "Cost:  0.0764618971415\n",
      "Cost:  0.0763633792881\n",
      "Cost:  0.0762651003355\n",
      "Cost:  0.076167059584\n",
      "Cost:  0.0760692563367\n",
      "Cost:  0.0759716898989\n",
      "Cost:  0.0758743595787\n",
      "Cost:  0.0757772646867\n",
      "Cost:  0.0756804045359\n",
      "Cost:  0.0755837784418\n",
      "Cost:  0.0754873857226\n",
      "Cost:  0.0753912256988\n",
      "Cost:  0.0752952976934\n",
      "Cost:  0.0751996010318\n",
      "Cost:  0.075104135042\n",
      "Cost:  0.0750088990543\n",
      "Cost:  0.0749138924016\n",
      "Cost:  0.0748191144189\n",
      "Cost:  0.074724564444\n",
      "Cost:  0.0746302418169\n",
      "Cost:  0.0745361458798\n",
      "Cost:  0.0744422759777\n",
      "Cost:  0.0743486314575\n",
      "Cost:  0.0742552116689\n",
      "Cost:  0.0741620159636\n",
      "Cost:  0.0740690436957\n",
      "Cost:  0.0739762942218\n",
      "Cost:  0.0738837669007\n",
      "Cost:  0.0737914610934\n",
      "Cost:  0.0736993761634\n",
      "Cost:  0.0736075114762\n",
      "Cost:  0.0735158664\n",
      "Cost:  0.0734244403048\n",
      "Cost:  0.0733332325631\n",
      "Cost:  0.0732422425497\n",
      "Cost:  0.0731514696414\n",
      "Cost:  0.0730609132175\n",
      "Cost:  0.0729705726593\n",
      "Cost:  0.0728804473505\n",
      "Cost:  0.0727905366767\n",
      "Cost:  0.0727008400259\n",
      "Cost:  0.0726113567883\n",
      "Cost:  0.0725220863563\n",
      "Cost:  0.0724330281242\n",
      "Cost:  0.0723441814887\n",
      "Cost:  0.0722555458485\n",
      "Cost:  0.0721671206045\n",
      "Cost:  0.0720789051597\n",
      "Cost:  0.0719908989193\n",
      "Cost:  0.0719031012904\n",
      "Cost:  0.0718155116823\n",
      "Cost:  0.0717281295066\n",
      "Cost:  0.0716409541765\n",
      "Cost:  0.0715539851078\n",
      "Cost:  0.0714672217179\n",
      "Cost:  0.0713806634265\n",
      "Cost:  0.0712943096553\n",
      "Cost:  0.071208159828\n",
      "Cost:  0.0711222133704\n",
      "Cost:  0.0710364697102\n",
      "Cost:  0.0709509282772\n",
      "Cost:  0.0708655885031\n",
      "Cost:  0.0707804498217\n",
      "Cost:  0.0706955116687\n",
      "Cost:  0.0706107734818\n",
      "Cost:  0.0705262347007\n",
      "Cost:  0.070441894767\n",
      "Cost:  0.0703577531242\n",
      "Cost:  0.070273809218\n",
      "Cost:  0.0701900624956\n",
      "Cost:  0.0701065124065\n",
      "Cost:  0.0700231584019\n",
      "Cost:  0.0699399999351\n",
      "Cost:  0.069857036461\n",
      "Cost:  0.0697742674367\n",
      "Cost:  0.069691692321\n",
      "Cost:  0.069691692321\n",
      "m:  [-0.53356387858819521, -0.45334445756381669, -3.307565422754394]\n",
      "Cost:  0.069691692321\n",
      "Cost  0.069691692321\n",
      "\n",
      "\n",
      "Cost:  0.0696093105746\n",
      "Cost:  0.0695271216602\n",
      "Cost:  0.0694451250421\n",
      "Cost:  0.0693633201867\n",
      "Cost:  0.0692817065622\n",
      "Cost:  0.0692002836384\n",
      "Cost:  0.0691190508872\n",
      "Cost:  0.0690380077823\n",
      "Cost:  0.068957153799\n",
      "Cost:  0.0688764884146\n",
      "Cost:  0.0687960111082\n",
      "Cost:  0.0687157213606\n",
      "Cost:  0.0686356186543\n",
      "Cost:  0.0685557024739\n",
      "Cost:  0.0684759723054\n",
      "Cost:  0.0683964276367\n",
      "Cost:  0.0683170679576\n",
      "Cost:  0.0682378927594\n",
      "Cost:  0.0681589015353\n",
      "Cost:  0.0680800937801\n",
      "Cost:  0.0680014689906\n",
      "Cost:  0.0679230266649\n",
      "Cost:  0.0678447663032\n",
      "Cost:  0.0677666874071\n",
      "Cost:  0.0676887894802\n",
      "Cost:  0.0676110720275\n",
      "Cost:  0.0675335345558\n",
      "Cost:  0.0674561765736\n",
      "Cost:  0.0673789975911\n",
      "Cost:  0.06730199712\n",
      "Cost:  0.0672251746739\n",
      "Cost:  0.0671485297677\n",
      "Cost:  0.0670720619184\n",
      "Cost:  0.0669957706441\n",
      "Cost:  0.0669196554651\n",
      "Cost:  0.0668437159028\n",
      "Cost:  0.0667679514806\n",
      "Cost:  0.0666923617232\n",
      "Cost:  0.0666169461572\n",
      "Cost:  0.0665417043105\n",
      "Cost:  0.0664666357129\n",
      "Cost:  0.0663917398954\n",
      "Cost:  0.066317016391\n",
      "Cost:  0.0662424647339\n",
      "Cost:  0.0661680844601\n",
      "Cost:  0.0660938751071\n",
      "Cost:  0.0660198362138\n",
      "Cost:  0.0659459673209\n",
      "Cost:  0.0658722679704\n",
      "Cost:  0.0657987377059\n",
      "Cost:  0.0657253760727\n",
      "Cost:  0.0656521826174\n",
      "Cost:  0.0655791568881\n",
      "Cost:  0.0655062984346\n",
      "Cost:  0.0654336068081\n",
      "Cost:  0.0653610815613\n",
      "Cost:  0.0652887222482\n",
      "Cost:  0.0652165284246\n",
      "Cost:  0.0651444996476\n",
      "Cost:  0.0650726354758\n",
      "Cost:  0.0650009354692\n",
      "Cost:  0.0649293991894\n",
      "Cost:  0.0648580261993\n",
      "Cost:  0.0647868160634\n",
      "Cost:  0.0647157683476\n",
      "Cost:  0.064644882619\n",
      "Cost:  0.0645741584464\n",
      "Cost:  0.0645035954\n",
      "Cost:  0.0644331930514\n",
      "Cost:  0.0643629509734\n",
      "Cost:  0.0642928687405\n",
      "Cost:  0.0642229459285\n",
      "Cost:  0.0641531821144\n",
      "Cost:  0.064083576877\n",
      "Cost:  0.0640141297961\n",
      "Cost:  0.0639448404531\n",
      "Cost:  0.0638757084306\n",
      "Cost:  0.0638067333127\n",
      "Cost:  0.0637379146848\n",
      "Cost:  0.0636692521338\n",
      "Cost:  0.0636007452478\n",
      "Cost:  0.0635323936161\n",
      "Cost:  0.0634641968297\n",
      "Cost:  0.0633961544807\n",
      "Cost:  0.0633282661626\n",
      "Cost:  0.0632605314702\n",
      "Cost:  0.0631929499996\n",
      "Cost:  0.0631255213482\n",
      "Cost:  0.0630582451149\n",
      "Cost:  0.0629911208996\n",
      "Cost:  0.0629241483037\n",
      "Cost:  0.0628573269298\n",
      "Cost:  0.062790656382\n",
      "Cost:  0.0627241362653\n",
      "Cost:  0.0626577661863\n",
      "Cost:  0.0625915457528\n",
      "Cost:  0.0625254745738\n",
      "Cost:  0.0624595522595\n",
      "Cost:  0.0623937784217\n",
      "Cost:  0.0623281526729\n",
      "Cost:  0.0623281526729\n",
      "m:  [-0.56948306553884176, -0.48591337837001791, -3.5278245312492125]\n",
      "Cost:  0.0623281526729\n",
      "Cost  0.0623281526729\n",
      "\n",
      "\n",
      "Cost:  0.0622626746274\n",
      "Cost:  0.0621973439004\n",
      "Cost:  0.0621321601084\n",
      "Cost:  0.0620671228692\n",
      "Cost:  0.0620022318019\n",
      "Cost:  0.0619374865267\n",
      "Cost:  0.0618728866649\n",
      "Cost:  0.0618084318393\n",
      "Cost:  0.0617441216737\n",
      "Cost:  0.0616799557932\n",
      "Cost:  0.0616159338241\n",
      "Cost:  0.0615520553939\n",
      "Cost:  0.0614883201312\n",
      "Cost:  0.0614247276658\n",
      "Cost:  0.0613612776288\n",
      "Cost:  0.0612979696524\n",
      "Cost:  0.0612348033701\n",
      "Cost:  0.0611717784162\n",
      "Cost:  0.0611088944266\n",
      "Cost:  0.0610461510381\n",
      "Cost:  0.0609835478888\n",
      "Cost:  0.0609210846178\n",
      "Cost:  0.0608587608654\n",
      "Cost:  0.0607965762732\n",
      "Cost:  0.0607345304836\n",
      "Cost:  0.0606726231406\n",
      "Cost:  0.0606108538888\n",
      "Cost:  0.0605492223744\n",
      "Cost:  0.0604877282443\n",
      "Cost:  0.0604263711469\n",
      "Cost:  0.0603651507315\n",
      "Cost:  0.0603040666485\n",
      "Cost:  0.0602431185494\n",
      "Cost:  0.0601823060869\n",
      "Cost:  0.0601216289148\n",
      "Cost:  0.0600610866878\n",
      "Cost:  0.0600006790619\n",
      "Cost:  0.059940405694\n",
      "Cost:  0.0598802662423\n",
      "Cost:  0.0598202603659\n",
      "Cost:  0.0597603877249\n",
      "Cost:  0.0597006479807\n",
      "Cost:  0.0596410407957\n",
      "Cost:  0.0595815658331\n",
      "Cost:  0.0595222227575\n",
      "Cost:  0.0594630112344\n",
      "Cost:  0.0594039309303\n",
      "Cost:  0.0593449815128\n",
      "Cost:  0.0592861626505\n",
      "Cost:  0.0592274740131\n",
      "Cost:  0.0591689152713\n",
      "Cost:  0.0591104860967\n",
      "Cost:  0.0590521861622\n",
      "Cost:  0.0589940151414\n",
      "Cost:  0.0589359727092\n",
      "Cost:  0.0588780585413\n",
      "Cost:  0.0588202723145\n",
      "Cost:  0.0587626137065\n",
      "Cost:  0.0587050823963\n",
      "Cost:  0.0586476780635\n",
      "Cost:  0.0585904003889\n",
      "Cost:  0.0585332490543\n",
      "Cost:  0.0584762237424\n",
      "Cost:  0.058419324137\n",
      "Cost:  0.0583625499227\n",
      "Cost:  0.0583059007853\n",
      "Cost:  0.0582493764113\n",
      "Cost:  0.0581929764884\n",
      "Cost:  0.0581367007051\n",
      "Cost:  0.058080548751\n",
      "Cost:  0.0580245203166\n",
      "Cost:  0.0579686150933\n",
      "Cost:  0.0579128327734\n",
      "Cost:  0.0578571730504\n",
      "Cost:  0.0578016356184\n",
      "Cost:  0.0577462201727\n",
      "Cost:  0.0576909264094\n",
      "Cost:  0.0576357540256\n",
      "Cost:  0.0575807027193\n",
      "Cost:  0.0575257721894\n",
      "Cost:  0.0574709621358\n",
      "Cost:  0.0574162722591\n",
      "Cost:  0.0573617022611\n",
      "Cost:  0.0573072518444\n",
      "Cost:  0.0572529207124\n",
      "Cost:  0.0571987085695\n",
      "Cost:  0.057144615121\n",
      "Cost:  0.0570906400732\n",
      "Cost:  0.057036783133\n",
      "Cost:  0.0569830440084\n",
      "Cost:  0.0569294224084\n",
      "Cost:  0.0568759180425\n",
      "Cost:  0.0568225306216\n",
      "Cost:  0.056769259857\n",
      "Cost:  0.0567161054611\n",
      "Cost:  0.0566630671472\n",
      "Cost:  0.0566101446293\n",
      "Cost:  0.0565573376225\n",
      "Cost:  0.0565046458426\n",
      "Cost:  0.0564520690062\n",
      "Cost:  0.0564520690062\n",
      "m:  [-0.60462706526791898, -0.51828182244580079, -3.7422936492803163]\n",
      "Cost:  0.0564520690062\n",
      "Cost  0.0564520690062\n",
      "\n",
      "\n",
      "Cost:  0.0563996068309\n",
      "Cost:  0.0563472590351\n",
      "Cost:  0.056295025338\n",
      "Cost:  0.0562429054598\n",
      "Cost:  0.0561908991213\n",
      "Cost:  0.0561390060444\n",
      "Cost:  0.0560872259516\n",
      "Cost:  0.0560355585664\n",
      "Cost:  0.055984003613\n",
      "Cost:  0.0559325608166\n",
      "Cost:  0.055881229903\n",
      "Cost:  0.0558300105991\n",
      "Cost:  0.0557789026323\n",
      "Cost:  0.055727905731\n",
      "Cost:  0.0556770196245\n",
      "Cost:  0.0556262440427\n",
      "Cost:  0.0555755787164\n",
      "Cost:  0.0555250233772\n",
      "Cost:  0.0554745777576\n",
      "Cost:  0.0554242415907\n",
      "Cost:  0.0553740146105\n",
      "Cost:  0.0553238965518\n",
      "Cost:  0.0552738871503\n",
      "Cost:  0.0552239861422\n",
      "Cost:  0.0551741932648\n",
      "Cost:  0.0551245082558\n",
      "Cost:  0.0550749308542\n",
      "Cost:  0.0550254607992\n",
      "Cost:  0.0549760978312\n",
      "Cost:  0.0549268416913\n",
      "Cost:  0.0548776921211\n",
      "Cost:  0.0548286488633\n",
      "Cost:  0.0547797116611\n",
      "Cost:  0.0547308802586\n",
      "Cost:  0.0546821544007\n",
      "Cost:  0.054633533833\n",
      "Cost:  0.0545850183017\n",
      "Cost:  0.0545366075539\n",
      "Cost:  0.0544883013375\n",
      "Cost:  0.0544400994011\n",
      "Cost:  0.0543920014939\n",
      "Cost:  0.0543440073659\n",
      "Cost:  0.054296116768\n",
      "Cost:  0.0542483294517\n",
      "Cost:  0.0542006451691\n",
      "Cost:  0.0541530636734\n",
      "Cost:  0.054105584718\n",
      "Cost:  0.0540582080575\n",
      "Cost:  0.054010933447\n",
      "Cost:  0.0539637606424\n",
      "Cost:  0.0539166894001\n",
      "Cost:  0.0538697194774\n",
      "Cost:  0.0538228506324\n",
      "Cost:  0.0537760826237\n",
      "Cost:  0.0537294152107\n",
      "Cost:  0.0536828481535\n",
      "Cost:  0.0536363812128\n",
      "Cost:  0.0535900141502\n",
      "Cost:  0.0535437467279\n",
      "Cost:  0.0534975787086\n",
      "Cost:  0.053451509856\n",
      "Cost:  0.0534055399343\n",
      "Cost:  0.0533596687085\n",
      "Cost:  0.053313895944\n",
      "Cost:  0.0532682214073\n",
      "Cost:  0.0532226448653\n",
      "Cost:  0.0531771660857\n",
      "Cost:  0.0531317848367\n",
      "Cost:  0.0530865008873\n",
      "Cost:  0.0530413140072\n",
      "Cost:  0.0529962239667\n",
      "Cost:  0.0529512305368\n",
      "Cost:  0.0529063334891\n",
      "Cost:  0.0528615325959\n",
      "Cost:  0.0528168276301\n",
      "Cost:  0.0527722183655\n",
      "Cost:  0.0527277045762\n",
      "Cost:  0.0526832860371\n",
      "Cost:  0.0526389625238\n",
      "Cost:  0.0525947338125\n",
      "Cost:  0.0525505996801\n",
      "Cost:  0.0525065599039\n",
      "Cost:  0.0524626142622\n",
      "Cost:  0.0524187625337\n",
      "Cost:  0.0523750044977\n",
      "Cost:  0.0523313399344\n",
      "Cost:  0.0522877686243\n",
      "Cost:  0.0522442903487\n",
      "Cost:  0.0522009048896\n",
      "Cost:  0.0521576120294\n",
      "Cost:  0.0521144115513\n",
      "Cost:  0.0520713032391\n",
      "Cost:  0.0520282868771\n",
      "Cost:  0.0519853622503\n",
      "Cost:  0.0519425291444\n",
      "Cost:  0.0518997873455\n",
      "Cost:  0.0518571366405\n",
      "Cost:  0.0518145768167\n",
      "Cost:  0.0517721076624\n",
      "Cost:  0.0517297289659\n",
      "Cost:  0.0517297289659\n",
      "m:  [-0.63914318191553343, -0.55053915793486885, -3.9520361220925859]\n",
      "Cost:  0.0517297289659\n",
      "Cost  0.0517297289659\n",
      "\n",
      "\n",
      "Cost:  0.0516874405167\n",
      "Cost:  0.0516452421045\n",
      "Cost:  0.0516031335198\n",
      "Cost:  0.0515611145535\n",
      "Cost:  0.0515191849974\n",
      "Cost:  0.0514773446435\n",
      "Cost:  0.0514355932847\n",
      "Cost:  0.0513939307143\n",
      "Cost:  0.0513523567264\n",
      "Cost:  0.0513108711154\n",
      "Cost:  0.0512694736764\n",
      "Cost:  0.0512281642052\n",
      "Cost:  0.0511869424981\n",
      "Cost:  0.0511458083517\n",
      "Cost:  0.0511047615637\n",
      "Cost:  0.051063801932\n",
      "Cost:  0.051022929255\n",
      "Cost:  0.050982143332\n",
      "Cost:  0.0509414439626\n",
      "Cost:  0.0509008309471\n",
      "Cost:  0.0508603040862\n",
      "Cost:  0.0508198631813\n",
      "Cost:  0.0507795080344\n",
      "Cost:  0.0507392384479\n",
      "Cost:  0.0506990542248\n",
      "Cost:  0.0506589551688\n",
      "Cost:  0.0506189410839\n",
      "Cost:  0.0505790117747\n",
      "Cost:  0.0505391670466\n",
      "Cost:  0.0504994067053\n",
      "Cost:  0.0504597305571\n",
      "Cost:  0.0504201384088\n",
      "Cost:  0.0503806300678\n",
      "Cost:  0.0503412053419\n",
      "Cost:  0.0503018640398\n",
      "Cost:  0.0502626059703\n",
      "Cost:  0.0502234309429\n",
      "Cost:  0.0501843387677\n",
      "Cost:  0.0501453292553\n",
      "Cost:  0.0501064022167\n",
      "Cost:  0.0500675574635\n",
      "Cost:  0.050028794808\n",
      "Cost:  0.0499901140627\n",
      "Cost:  0.0499515150408\n",
      "Cost:  0.0499129975561\n",
      "Cost:  0.0498745614227\n",
      "Cost:  0.0498362064553\n",
      "Cost:  0.0497979324692\n",
      "Cost:  0.0497597392801\n",
      "Cost:  0.0497216267042\n",
      "Cost:  0.0496835945584\n",
      "Cost:  0.0496456426599\n",
      "Cost:  0.0496077708264\n",
      "Cost:  0.0495699788761\n",
      "Cost:  0.049532266628\n",
      "Cost:  0.0494946339012\n",
      "Cost:  0.0494570805154\n",
      "Cost:  0.049419606291\n",
      "Cost:  0.0493822110487\n",
      "Cost:  0.0493448946097\n",
      "Cost:  0.0493076567957\n",
      "Cost:  0.049270497429\n",
      "Cost:  0.0492334163323\n",
      "Cost:  0.0491964133287\n",
      "Cost:  0.0491594882419\n",
      "Cost:  0.049122640896\n",
      "Cost:  0.0490858711158\n",
      "Cost:  0.0490491787262\n",
      "Cost:  0.049012563553\n",
      "Cost:  0.0489760254221\n",
      "Cost:  0.0489395641601\n",
      "Cost:  0.048903179594\n",
      "Cost:  0.0488668715512\n",
      "Cost:  0.0488306398598\n",
      "Cost:  0.0487944843482\n",
      "Cost:  0.0487584048451\n",
      "Cost:  0.0487224011801\n",
      "Cost:  0.0486864731828\n",
      "Cost:  0.0486506206835\n",
      "Cost:  0.0486148435131\n",
      "Cost:  0.0485791415026\n",
      "Cost:  0.0485435144838\n",
      "Cost:  0.0485079622886\n",
      "Cost:  0.0484724847498\n",
      "Cost:  0.0484370817002\n",
      "Cost:  0.0484017529734\n",
      "Cost:  0.0483664984033\n",
      "Cost:  0.0483313178242\n",
      "Cost:  0.0482962110709\n",
      "Cost:  0.0482611779788\n",
      "Cost:  0.0482262183833\n",
      "Cost:  0.0481913321209\n",
      "Cost:  0.0481565190279\n",
      "Cost:  0.0481217789414\n",
      "Cost:  0.0480871116989\n",
      "Cost:  0.0480525171382\n",
      "Cost:  0.0480179950977\n",
      "Cost:  0.0479835454162\n",
      "Cost:  0.0479491679329\n",
      "Cost:  0.0479148624873\n",
      "Cost:  0.0479148624873\n",
      "m:  [-0.67314429184712654, -0.58274749419466532, -4.157889365975028]\n",
      "Cost:  0.0479148624873\n",
      "Cost  0.0479148624873\n",
      "\n",
      "\n",
      "Cost:  0.0478806289196\n",
      "Cost:  0.0478464670701\n",
      "Cost:  0.0478123767799\n",
      "Cost:  0.0477783578903\n",
      "Cost:  0.047744410243\n",
      "Cost:  0.0477105336802\n",
      "Cost:  0.0476767280445\n",
      "Cost:  0.047642993179\n",
      "Cost:  0.047609328927\n",
      "Cost:  0.0475757351325\n",
      "Cost:  0.0475422116398\n",
      "Cost:  0.0475087582934\n",
      "Cost:  0.0474753749386\n",
      "Cost:  0.0474420614209\n",
      "Cost:  0.0474088175861\n",
      "Cost:  0.0473756432806\n",
      "Cost:  0.0473425383512\n",
      "Cost:  0.0473095026451\n",
      "Cost:  0.0472765360097\n",
      "Cost:  0.047243638293\n",
      "Cost:  0.0472108093435\n",
      "Cost:  0.0471780490098\n",
      "Cost:  0.0471453571412\n",
      "Cost:  0.0471127335872\n",
      "Cost:  0.0470801781978\n",
      "Cost:  0.0470476908234\n",
      "Cost:  0.0470152713146\n",
      "Cost:  0.0469829195228\n",
      "Cost:  0.0469506352993\n",
      "Cost:  0.0469184184962\n",
      "Cost:  0.0468862689657\n",
      "Cost:  0.0468541865607\n",
      "Cost:  0.0468221711341\n",
      "Cost:  0.0467902225396\n",
      "Cost:  0.0467583406309\n",
      "Cost:  0.0467265252623\n",
      "Cost:  0.0466947762885\n",
      "Cost:  0.0466630935645\n",
      "Cost:  0.0466314769457\n",
      "Cost:  0.0465999262879\n",
      "Cost:  0.0465684414473\n",
      "Cost:  0.0465370222804\n",
      "Cost:  0.046505668644\n",
      "Cost:  0.0464743803956\n",
      "Cost:  0.0464431573928\n",
      "Cost:  0.0464119994936\n",
      "Cost:  0.0463809065564\n",
      "Cost:  0.0463498784401\n",
      "Cost:  0.0463189150037\n",
      "Cost:  0.0462880161067\n",
      "Cost:  0.0462571816091\n",
      "Cost:  0.0462264113712\n",
      "Cost:  0.0461957052534\n",
      "Cost:  0.0461650631168\n",
      "Cost:  0.0461344848228\n",
      "Cost:  0.046103970233\n",
      "Cost:  0.0460735192094\n",
      "Cost:  0.0460431316146\n",
      "Cost:  0.0460128073112\n",
      "Cost:  0.0459825461625\n",
      "Cost:  0.0459523480319\n",
      "Cost:  0.0459222127831\n",
      "Cost:  0.0458921402806\n",
      "Cost:  0.0458621303887\n",
      "Cost:  0.0458321829723\n",
      "Cost:  0.0458022978968\n",
      "Cost:  0.0457724750277\n",
      "Cost:  0.0457427142309\n",
      "Cost:  0.0457130153728\n",
      "Cost:  0.0456833783199\n",
      "Cost:  0.0456538029393\n",
      "Cost:  0.0456242890983\n",
      "Cost:  0.0455948366645\n",
      "Cost:  0.045565445506\n",
      "Cost:  0.0455361154911\n",
      "Cost:  0.0455068464884\n",
      "Cost:  0.045477638367\n",
      "Cost:  0.0454484909963\n",
      "Cost:  0.0454194042459\n",
      "Cost:  0.045390377986\n",
      "Cost:  0.0453614120867\n",
      "Cost:  0.045332506419\n",
      "Cost:  0.0453036608537\n",
      "Cost:  0.0452748752622\n",
      "Cost:  0.0452461495162\n",
      "Cost:  0.0452174834878\n",
      "Cost:  0.0451888770493\n",
      "Cost:  0.0451603300734\n",
      "Cost:  0.045131842433\n",
      "Cost:  0.0451034140015\n",
      "Cost:  0.0450750446525\n",
      "Cost:  0.04504673426\n",
      "Cost:  0.0450184826984\n",
      "Cost:  0.0449902898421\n",
      "Cost:  0.0449621555662\n",
      "Cost:  0.0449340797459\n",
      "Cost:  0.0449060622568\n",
      "Cost:  0.0448781029747\n",
      "Cost:  0.0448502017758\n",
      "Cost:  0.0448223585367\n",
      "Cost:  0.0448223585367\n",
      "m:  [-0.70671801565524106, -0.6149498445940057, -4.3605201796566266]\n",
      "Cost:  0.0448223585367\n",
      "Cost  0.0448223585367\n",
      "\n",
      "\n",
      "Cost:  0.0447945731343\n",
      "Cost:  0.0447668454456\n",
      "Cost:  0.044739175348\n",
      "Cost:  0.0447115627195\n",
      "Cost:  0.044684007438\n",
      "Cost:  0.044656509382\n",
      "Cost:  0.0446290684301\n",
      "Cost:  0.0446016844613\n",
      "Cost:  0.044574357355\n",
      "Cost:  0.0445470869907\n",
      "Cost:  0.0445198732485\n",
      "Cost:  0.0444927160084\n",
      "Cost:  0.0444656151511\n",
      "Cost:  0.0444385705574\n",
      "Cost:  0.0444115821083\n",
      "Cost:  0.0443846496854\n",
      "Cost:  0.0443577731703\n",
      "Cost:  0.0443309524451\n",
      "Cost:  0.0443041873922\n",
      "Cost:  0.044277477894\n",
      "Cost:  0.0442508238336\n",
      "Cost:  0.0442242250941\n",
      "Cost:  0.0441976815592\n",
      "Cost:  0.0441711931124\n",
      "Cost:  0.044144759638\n",
      "Cost:  0.0441183810204\n",
      "Cost:  0.0440920571441\n",
      "Cost:  0.0440657878943\n",
      "Cost:  0.044039573156\n",
      "Cost:  0.0440134128149\n",
      "Cost:  0.0439873067567\n",
      "Cost:  0.0439612548677\n",
      "Cost:  0.0439352570341\n",
      "Cost:  0.0439093131427\n",
      "Cost:  0.0438834230804\n",
      "Cost:  0.0438575867344\n",
      "Cost:  0.0438318039924\n",
      "Cost:  0.0438060747421\n",
      "Cost:  0.0437803988715\n",
      "Cost:  0.0437547762691\n",
      "Cost:  0.0437292068235\n",
      "Cost:  0.0437036904237\n",
      "Cost:  0.0436782269588\n",
      "Cost:  0.0436528163182\n",
      "Cost:  0.0436274583919\n",
      "Cost:  0.0436021530697\n",
      "Cost:  0.0435769002419\n",
      "Cost:  0.0435516997993\n",
      "Cost:  0.0435265516325\n",
      "Cost:  0.0435014556327\n",
      "Cost:  0.0434764116913\n",
      "Cost:  0.0434514197\n",
      "Cost:  0.0434264795506\n",
      "Cost:  0.0434015911354\n",
      "Cost:  0.0433767543468\n",
      "Cost:  0.0433519690775\n",
      "Cost:  0.0433272352206\n",
      "Cost:  0.0433025526692\n",
      "Cost:  0.0432779213169\n",
      "Cost:  0.0432533410575\n",
      "Cost:  0.0432288117851\n",
      "Cost:  0.0432043333938\n",
      "Cost:  0.0431799057784\n",
      "Cost:  0.0431555288335\n",
      "Cost:  0.0431312024544\n",
      "Cost:  0.0431069265363\n",
      "Cost:  0.0430827009749\n",
      "Cost:  0.0430585256659\n",
      "Cost:  0.0430344005056\n",
      "Cost:  0.0430103253902\n",
      "Cost:  0.0429863002165\n",
      "Cost:  0.0429623248813\n",
      "Cost:  0.0429383992817\n",
      "Cost:  0.042914523315\n",
      "Cost:  0.0428906968791\n",
      "Cost:  0.0428669198716\n",
      "Cost:  0.0428431921908\n",
      "Cost:  0.0428195137351\n",
      "Cost:  0.0427958844031\n",
      "Cost:  0.0427723040936\n",
      "Cost:  0.0427487727059\n",
      "Cost:  0.0427252901392\n",
      "Cost:  0.0427018562932\n",
      "Cost:  0.0426784710678\n",
      "Cost:  0.0426551343631\n",
      "Cost:  0.0426318460794\n",
      "Cost:  0.0426086061174\n",
      "Cost:  0.0425854143779\n",
      "Cost:  0.0425622707619\n",
      "Cost:  0.0425391751708\n",
      "Cost:  0.0425161275063\n",
      "Cost:  0.0424931276699\n",
      "Cost:  0.0424701755639\n",
      "Cost:  0.0424472710905\n",
      "Cost:  0.0424244141522\n",
      "Cost:  0.0424016046518\n",
      "Cost:  0.0423788424923\n",
      "Cost:  0.0423561275768\n",
      "Cost:  0.042333459809\n",
      "Cost:  0.0423108390923\n",
      "Cost:  0.0423108390923\n",
      "m:  [-0.73993315328101605, -0.64717568475167442, -4.5604645962661303]\n",
      "Cost:  0.0423108390923\n",
      "Cost  0.0423108390923\n",
      "\n",
      "\n",
      "Cost:  0.0422882653309\n",
      "Cost:  0.0422657384288\n",
      "Cost:  0.0422432582905\n",
      "Cost:  0.0422208248206\n",
      "Cost:  0.0421984379238\n",
      "Cost:  0.0421760975055\n",
      "Cost:  0.0421538034707\n",
      "Cost:  0.0421315557252\n",
      "Cost:  0.0421093541746\n",
      "Cost:  0.0420871987249\n",
      "Cost:  0.0420650892825\n",
      "Cost:  0.0420430257537\n",
      "Cost:  0.0420210080453\n",
      "Cost:  0.041999036064\n",
      "Cost:  0.0419771097172\n",
      "Cost:  0.0419552289121\n",
      "Cost:  0.0419333935562\n",
      "Cost:  0.0419116035575\n",
      "Cost:  0.0418898588238\n",
      "Cost:  0.0418681592636\n",
      "Cost:  0.0418465047851\n",
      "Cost:  0.0418248952971\n",
      "Cost:  0.0418033307086\n",
      "Cost:  0.0417818109285\n",
      "Cost:  0.0417603358663\n",
      "Cost:  0.0417389054316\n",
      "Cost:  0.041717519534\n",
      "Cost:  0.0416961780835\n",
      "Cost:  0.0416748809905\n",
      "Cost:  0.0416536281652\n",
      "Cost:  0.0416324195183\n",
      "Cost:  0.0416112549607\n",
      "Cost:  0.0415901344035\n",
      "Cost:  0.0415690577578\n",
      "Cost:  0.0415480249352\n",
      "Cost:  0.0415270358474\n",
      "Cost:  0.0415060904062\n",
      "Cost:  0.0414851885238\n",
      "Cost:  0.0414643301126\n",
      "Cost:  0.041443515085\n",
      "Cost:  0.0414227433538\n",
      "Cost:  0.0414020148319\n",
      "Cost:  0.0413813294325\n",
      "Cost:  0.0413606870689\n",
      "Cost:  0.0413400876548\n",
      "Cost:  0.0413195311038\n",
      "Cost:  0.04129901733\n",
      "Cost:  0.0412785462476\n",
      "Cost:  0.0412581177709\n",
      "Cost:  0.0412377318146\n",
      "Cost:  0.0412173882933\n",
      "Cost:  0.0411970871222\n",
      "Cost:  0.0411768282163\n",
      "Cost:  0.0411566114912\n",
      "Cost:  0.0411364368624\n",
      "Cost:  0.0411163042456\n",
      "Cost:  0.0410962135569\n",
      "Cost:  0.0410761647125\n",
      "Cost:  0.0410561576288\n",
      "Cost:  0.0410361922223\n",
      "Cost:  0.0410162684098\n",
      "Cost:  0.0409963861084\n",
      "Cost:  0.0409765452352\n",
      "Cost:  0.0409567457075\n",
      "Cost:  0.0409369874429\n",
      "Cost:  0.0409172703593\n",
      "Cost:  0.0408975943745\n",
      "Cost:  0.0408779594067\n",
      "Cost:  0.0408583653742\n",
      "Cost:  0.0408388121955\n",
      "Cost:  0.0408192997895\n",
      "Cost:  0.040799828075\n",
      "Cost:  0.040780396971\n",
      "Cost:  0.040761006397\n",
      "Cost:  0.0407416562723\n",
      "Cost:  0.0407223465167\n",
      "Cost:  0.04070307705\n",
      "Cost:  0.0406838477923\n",
      "Cost:  0.0406646586638\n",
      "Cost:  0.0406455095848\n",
      "Cost:  0.0406264004761\n",
      "Cost:  0.0406073312585\n",
      "Cost:  0.0405883018528\n",
      "Cost:  0.0405693121803\n",
      "Cost:  0.0405503621623\n",
      "Cost:  0.0405314517203\n",
      "Cost:  0.0405125807761\n",
      "Cost:  0.0404937492515\n",
      "Cost:  0.0404749570687\n",
      "Cost:  0.0404562041498\n",
      "Cost:  0.0404374904174\n",
      "Cost:  0.0404188157941\n",
      "Cost:  0.0404001802026\n",
      "Cost:  0.0403815835659\n",
      "Cost:  0.0403630258072\n",
      "Cost:  0.0403445068499\n",
      "Cost:  0.0403260266174\n",
      "Cost:  0.0403075850335\n",
      "Cost:  0.040289182022\n",
      "Cost:  0.040270817507\n",
      "Cost:  0.040270817507\n",
      "m:  [-0.77284428572403641, -0.679444810245312, -4.7581571184514981]\n",
      "Cost:  0.040270817507\n",
      "Cost  0.040270817507\n",
      "\n",
      "\n",
      "Cost:  0.0402524914127\n",
      "Cost:  0.0402342036635\n",
      "Cost:  0.0402159541839\n",
      "Cost:  0.0401977428988\n",
      "Cost:  0.040179569733\n",
      "Cost:  0.0401614346117\n",
      "Cost:  0.0401433374601\n",
      "Cost:  0.0401252782037\n",
      "Cost:  0.0401072567681\n",
      "Cost:  0.040089273079\n",
      "Cost:  0.0400713270625\n",
      "Cost:  0.0400534186447\n",
      "Cost:  0.0400355477518\n",
      "Cost:  0.0400177143103\n",
      "Cost:  0.039999918247\n",
      "Cost:  0.0399821594885\n",
      "Cost:  0.039964437962\n",
      "Cost:  0.0399467535944\n",
      "Cost:  0.0399291063132\n",
      "Cost:  0.0399114960458\n",
      "Cost:  0.0398939227199\n",
      "Cost:  0.0398763862632\n",
      "Cost:  0.0398588866039\n",
      "Cost:  0.0398414236699\n",
      "Cost:  0.0398239973897\n",
      "Cost:  0.0398066076917\n",
      "Cost:  0.0397892545046\n",
      "Cost:  0.039771937757\n",
      "Cost:  0.0397546573782\n",
      "Cost:  0.039737413297\n",
      "Cost:  0.0397202054429\n",
      "Cost:  0.0397030337453\n",
      "Cost:  0.0396858981339\n",
      "Cost:  0.0396687985383\n",
      "Cost:  0.0396517348885\n",
      "Cost:  0.0396347071147\n",
      "Cost:  0.039617715147\n",
      "Cost:  0.039600758916\n",
      "Cost:  0.0395838383522\n",
      "Cost:  0.0395669533862\n",
      "Cost:  0.0395501039491\n",
      "Cost:  0.0395332899718\n",
      "Cost:  0.0395165113856\n",
      "Cost:  0.0394997681218\n",
      "Cost:  0.039483060112\n",
      "Cost:  0.0394663872878\n",
      "Cost:  0.0394497495811\n",
      "Cost:  0.0394331469238\n",
      "Cost:  0.0394165792481\n",
      "Cost:  0.0394000464863\n",
      "Cost:  0.0393835485708\n",
      "Cost:  0.0393670854343\n",
      "Cost:  0.0393506570095\n",
      "Cost:  0.0393342632292\n",
      "Cost:  0.0393179040266\n",
      "Cost:  0.0393015793349\n",
      "Cost:  0.0392852890875\n",
      "Cost:  0.0392690332178\n",
      "Cost:  0.0392528116595\n",
      "Cost:  0.0392366243465\n",
      "Cost:  0.0392204712126\n",
      "Cost:  0.0392043521921\n",
      "Cost:  0.0391882672192\n",
      "Cost:  0.0391722162283\n",
      "Cost:  0.0391561991539\n",
      "Cost:  0.0391402159308\n",
      "Cost:  0.0391242664938\n",
      "Cost:  0.039108350778\n",
      "Cost:  0.0390924687184\n",
      "Cost:  0.0390766202504\n",
      "Cost:  0.0390608053094\n",
      "Cost:  0.039045023831\n",
      "Cost:  0.039029275751\n",
      "Cost:  0.0390135610052\n",
      "Cost:  0.0389978795296\n",
      "Cost:  0.0389822312604\n",
      "Cost:  0.0389666161339\n",
      "Cost:  0.0389510340866\n",
      "Cost:  0.038935485055\n",
      "Cost:  0.0389199689759\n",
      "Cost:  0.0389044857862\n",
      "Cost:  0.0388890354229\n",
      "Cost:  0.0388736178231\n",
      "Cost:  0.0388582329242\n",
      "Cost:  0.0388428806637\n",
      "Cost:  0.038827560979\n",
      "Cost:  0.0388122738079\n",
      "Cost:  0.0387970190883\n",
      "Cost:  0.0387817967581\n",
      "Cost:  0.0387666067556\n",
      "Cost:  0.038751449019\n",
      "Cost:  0.0387363234867\n",
      "Cost:  0.0387212300973\n",
      "Cost:  0.0387061687894\n",
      "Cost:  0.038691139502\n",
      "Cost:  0.0386761421738\n",
      "Cost:  0.0386611767442\n",
      "Cost:  0.0386462431523\n",
      "Cost:  0.0386313413374\n",
      "Cost:  0.0386164712391\n",
      "Cost:  0.0386164712391\n",
      "m:  [-0.8054951218537838, -0.71177005807659, -4.9539525153342527]\n",
      "Cost:  0.0386164712391\n",
      "Cost  0.0386164712391\n",
      "\n",
      "\n",
      "Cost:  0.038601632797\n",
      "Cost:  0.0385868259509\n",
      "Cost:  0.0385720506408\n",
      "Cost:  0.0385573068066\n",
      "Cost:  0.0385425943885\n",
      "Cost:  0.0385279133269\n",
      "Cost:  0.0385132635622\n",
      "Cost:  0.038498645035\n",
      "Cost:  0.0384840576859\n",
      "Cost:  0.0384695014559\n",
      "Cost:  0.0384549762858\n",
      "Cost:  0.0384404821168\n",
      "Cost:  0.0384260188902\n",
      "Cost:  0.0384115865473\n",
      "Cost:  0.0383971850295\n",
      "Cost:  0.0383828142786\n",
      "Cost:  0.0383684742362\n",
      "Cost:  0.0383541648442\n",
      "Cost:  0.0383398860447\n",
      "Cost:  0.0383256377798\n",
      "Cost:  0.0383114199918\n",
      "Cost:  0.038297232623\n",
      "Cost:  0.0382830756159\n",
      "Cost:  0.0382689489133\n",
      "Cost:  0.0382548524579\n",
      "Cost:  0.0382407861925\n",
      "Cost:  0.0382267500603\n",
      "Cost:  0.0382127440044\n",
      "Cost:  0.038198767968\n",
      "Cost:  0.0381848218945\n",
      "Cost:  0.0381709057276\n",
      "Cost:  0.0381570194107\n",
      "Cost:  0.0381431628878\n",
      "Cost:  0.0381293361027\n",
      "Cost:  0.0381155389994\n",
      "Cost:  0.0381017715221\n",
      "Cost:  0.038088033615\n",
      "Cost:  0.0380743252225\n",
      "Cost:  0.0380606462892\n",
      "Cost:  0.0380469967597\n",
      "Cost:  0.0380333765787\n",
      "Cost:  0.0380197856911\n",
      "Cost:  0.0380062240419\n",
      "Cost:  0.0379926915763\n",
      "Cost:  0.0379791882394\n",
      "Cost:  0.0379657139767\n",
      "Cost:  0.0379522687336\n",
      "Cost:  0.0379388524556\n",
      "Cost:  0.0379254650886\n",
      "Cost:  0.0379121065784\n",
      "Cost:  0.0378987768708\n",
      "Cost:  0.0378854759121\n",
      "Cost:  0.0378722036483\n",
      "Cost:  0.0378589600258\n",
      "Cost:  0.037845744991\n",
      "Cost:  0.0378325584905\n",
      "Cost:  0.0378194004709\n",
      "Cost:  0.0378062708789\n",
      "Cost:  0.0377931696615\n",
      "Cost:  0.0377800967657\n",
      "Cost:  0.0377670521386\n",
      "Cost:  0.0377540357274\n",
      "Cost:  0.0377410474795\n",
      "Cost:  0.0377280873424\n",
      "Cost:  0.0377151552636\n",
      "Cost:  0.0377022511909\n",
      "Cost:  0.0376893750719\n",
      "Cost:  0.0376765268548\n",
      "Cost:  0.0376637064874\n",
      "Cost:  0.0376509139179\n",
      "Cost:  0.0376381490947\n",
      "Cost:  0.037625411966\n",
      "Cost:  0.0376127024804\n",
      "Cost:  0.0376000205865\n",
      "Cost:  0.0375873662329\n",
      "Cost:  0.0375747393684\n",
      "Cost:  0.0375621399421\n",
      "Cost:  0.037549567903\n",
      "Cost:  0.0375370232001\n",
      "Cost:  0.0375245057828\n",
      "Cost:  0.0375120156004\n",
      "Cost:  0.0374995526024\n",
      "Cost:  0.0374871167384\n",
      "Cost:  0.0374747079581\n",
      "Cost:  0.0374623262113\n",
      "Cost:  0.0374499714479\n",
      "Cost:  0.0374376436179\n",
      "Cost:  0.0374253426715\n",
      "Cost:  0.0374130685589\n",
      "Cost:  0.0374008212305\n",
      "Cost:  0.0373886006366\n",
      "Cost:  0.0373764067279\n",
      "Cost:  0.037364239455\n",
      "Cost:  0.0373520987687\n",
      "Cost:  0.0373399846199\n",
      "Cost:  0.0373278969595\n",
      "Cost:  0.0373158357387\n",
      "Cost:  0.0373038009086\n",
      "Cost:  0.0372917924205\n",
      "Cost:  0.0372798102259\n",
      "Cost:  0.0372798102259\n",
      "m:  [-0.83792096928501003, -0.74415925288715479, -5.1481423115211697]\n",
      "Cost:  0.0372798102259\n",
      "Cost  0.0372798102259\n",
      "\n",
      "\n",
      "Cost:  0.0372678542762\n",
      "Cost:  0.037255924523\n",
      "Cost:  0.0372440209181\n",
      "Cost:  0.0372321434133\n",
      "Cost:  0.0372202919605\n",
      "Cost:  0.0372084665117\n",
      "Cost:  0.0371966670191\n",
      "Cost:  0.0371848934349\n",
      "Cost:  0.0371731457113\n",
      "Cost:  0.037161423801\n",
      "Cost:  0.0371497276563\n",
      "Cost:  0.03713805723\n",
      "Cost:  0.0371264124747\n",
      "Cost:  0.0371147933433\n",
      "Cost:  0.0371031997888\n",
      "Cost:  0.0370916317641\n",
      "Cost:  0.0370800892225\n",
      "Cost:  0.0370685721171\n",
      "Cost:  0.0370570804014\n",
      "Cost:  0.0370456140287\n",
      "Cost:  0.0370341729526\n",
      "Cost:  0.0370227571268\n",
      "Cost:  0.0370113665048\n",
      "Cost:  0.0370000010407\n",
      "Cost:  0.0369886606884\n",
      "Cost:  0.0369773454018\n",
      "Cost:  0.0369660551351\n",
      "Cost:  0.0369547898425\n",
      "Cost:  0.0369435494784\n",
      "Cost:  0.0369323339972\n",
      "Cost:  0.0369211433533\n",
      "Cost:  0.0369099775015\n",
      "Cost:  0.0368988363963\n",
      "Cost:  0.0368877199928\n",
      "Cost:  0.0368766282456\n",
      "Cost:  0.0368655611099\n",
      "Cost:  0.0368545185407\n",
      "Cost:  0.0368435004932\n",
      "Cost:  0.0368325069227\n",
      "Cost:  0.0368215377846\n",
      "Cost:  0.0368105930343\n",
      "Cost:  0.0367996726275\n",
      "Cost:  0.0367887765198\n",
      "Cost:  0.0367779046669\n",
      "Cost:  0.0367670570247\n",
      "Cost:  0.0367562335491\n",
      "Cost:  0.0367454341962\n",
      "Cost:  0.0367346589221\n",
      "Cost:  0.036723907683\n",
      "Cost:  0.0367131804353\n",
      "Cost:  0.0367024771353\n",
      "Cost:  0.0366917977395\n",
      "Cost:  0.0366811422046\n",
      "Cost:  0.0366705104872\n",
      "Cost:  0.036659902544\n",
      "Cost:  0.036649318332\n",
      "Cost:  0.0366387578082\n",
      "Cost:  0.0366282209294\n",
      "Cost:  0.036617707653\n",
      "Cost:  0.036607217936\n",
      "Cost:  0.0365967517359\n",
      "Cost:  0.03658630901\n",
      "Cost:  0.0365758897158\n",
      "Cost:  0.0365654938109\n",
      "Cost:  0.036555121253\n",
      "Cost:  0.0365447719999\n",
      "Cost:  0.0365344460093\n",
      "Cost:  0.0365241432393\n",
      "Cost:  0.0365138636479\n",
      "Cost:  0.0365036071931\n",
      "Cost:  0.0364933738332\n",
      "Cost:  0.0364831635264\n",
      "Cost:  0.0364729762312\n",
      "Cost:  0.0364628119061\n",
      "Cost:  0.0364526705094\n",
      "Cost:  0.036442552\n",
      "Cost:  0.0364324563365\n",
      "Cost:  0.0364223834778\n",
      "Cost:  0.0364123333827\n",
      "Cost:  0.0364023060102\n",
      "Cost:  0.0363923013194\n",
      "Cost:  0.0363823192694\n",
      "Cost:  0.0363723598196\n",
      "Cost:  0.0363624229291\n",
      "Cost:  0.0363525085575\n",
      "Cost:  0.0363426166642\n",
      "Cost:  0.0363327472087\n",
      "Cost:  0.0363229001509\n",
      "Cost:  0.0363130754503\n",
      "Cost:  0.0363032730669\n",
      "Cost:  0.0362934929605\n",
      "Cost:  0.0362837350911\n",
      "Cost:  0.0362739994189\n",
      "Cost:  0.036264285904\n",
      "Cost:  0.0362545945066\n",
      "Cost:  0.0362449251871\n",
      "Cost:  0.0362352779059\n",
      "Cost:  0.0362256526234\n",
      "Cost:  0.0362160493004\n"
     ]
    }
   ],
   "source": [
    "# Run the Classifier\n",
    "\n",
    "[m,hist] = runner(X,y,learning_Rate,initial_m,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of m after 2000 iterations is m1 = -0.8698291769049067, m2 = -0.7762916960867493, m3 = -5.33904524111204\n"
     ]
    }
   ],
   "source": [
    "# Final Cost\n",
    "\n",
    "print('Value of m after {0} iterations is m1 = {1}, m2 = {2}, m3 = {3}'.format(iterations,m[0],m[1],m[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can clearly see that the Cost decreases and after 2000 iterations we have the values for our three slopes i.e. m1, m2 and m3.\n",
    "\n",
    "Let's plot the Cost Function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2453658ad68>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHiCAYAAAAqFoLhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAB8QrACAADwCcEKAADAJwQrAAAAn/z/7oYkNTCYJL4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2453657c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Cost Function Decay\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "ax.plot(hist)\n",
    "ax.set_title('Cost Decay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function plot shows that how it decays and becomes stable after 2000 iterations.\n",
    "\n",
    "#### I hope this tutorial was informative enough. For any comments, suggestions, corrections, please feel free to leave them below. Thanks :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
